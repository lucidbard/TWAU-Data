ABSTRACT
Welcome to the CHI 2007 proceedings. We believe the technical papers and notes herein present some of the best current work in the diverse and dynamic field of human-computer interaction (HCI).

CHI is the leading HCI conference. Creating the technical program requires a huge investment of time and effort from members of the research community. 840 submissions were processed (571 papers, 269 notes), requiring over 3000 reviews. We thank all the reviewers for the dedication with which they undertook this task. We are particularly indebted to the papers and notes program committee members, also known as the Associate Chairs (ACs). Balancing areas of expertise, ACs were selected from the field's leading researchers. The AC role included recruiting all reviewers, moderating and supervising the review process to ensure a high-quality set of reviews was obtained, initiating and organizing author rebuttal and reviewer discussions and approving final submissions. The estimated time expenditure to serve as an AC was 11 days of full-time work; many committee members spent more time than that. Papers ACs came to San Jose in December 2006 from around the world for two intense days of review, debates, and deliberation; Notes ACs who could not attend the parallel notes meeting in San Jose engaged in a virtual conference. The committee was extremely serious and careful in making CHI paper and note decisions, with many submissions receiving multiple discussions, before and during the program committee meetings. No review process can guarantee perfect decisions, but we are confident that every possible effort was made to ensure fair process and high quality decision-making. This year's program committee certainly has our respect and gratitude, and deserves the sincere appreciation of the entire HCI community. We would also like to thank the ACs and their organizations for underwriting the travel expenses for meeting.

CHI is both a journal-quality archival forum and a community-building conference. To encourage quality in the written presentation of accepted work, all of the 142 full paper and 40 note acceptances were provisional. As a result, authors actively responded and incorporated feedback from the reviews into the final versions of the papers that appear here.

Twenty-eight accepted papers and four accepted notes (5% of submissions) deemed to make an especially noteworthy contribution to human-computer interaction research were nominated by the program committee for Best Paper and Best Note Awards; these nominated papers and notes are identified in the Final Program. At the conference, up to six of these will be announced as winners of a CHI Best Paper Award (1% of submissions), and one note will be selected as an exemplary note. While all papers accepted into the CHI technical papers program have passed a rigorous examination of their quality, the Best Paper and Best Notes Awards signal and reward particularly outstanding contributions in each year.

 top of pageSOURCE MATERIALS
FRONT MATTER
 PDFPDF  (title page, copyright, contents, chair's welcome, welcome from the papers and notes chairs, from ACM SIGCHI's president and vice president for conferences, about SIGCHI and ACM, organization, sponsors & supporters)
BACK MATTER
 PDFPDF  (author index, keyword index)
APPEARS IN
Interaction

top of pageAUTHORS
General Chairs


Author image not provided	 Mary Beth Rosson

No contact information provided yet.
Bibliometrics: publication history
Publication years	1982-2017
Publication count	228
Citation Count	2,793
Available for download	136
Downloads (6 Weeks)	829
Downloads (12 Months)	6,131
Downloads (cumulative)	94,963
Average downloads per article	698.26
Average citations per article	12.25
View colleagues of Mary Beth Rosson
Program Chairs


Author image not provided	 David Gilmore

No contact information provided yet.
Bibliometrics: publication history
Publication years	1984-2012
Publication count	17
Citation Count	55
Available for download	11
Downloads (6 Weeks)	21
Downloads (12 Months)	132
Downloads (cumulative)	4,361
Average downloads per article	396.45
Average citations per article	3.24
View colleagues of David Gilmore
 top of pageREFERENCES
References are not available
top of pageCITED BY
Citings are not available
top of pageINDEX TERMS
Index Terms are not available
top of pagePUBLICATION
Title	CHI '07 CHI Conference on Human Factors in Computing Systems
San Jose, CA, USA — April 30 - May 03, 2007
Pages	1624
Sponsors	SIGCHI ACM Special Interest Group on Computer-Human Interaction
ACM Association for Computing Machinery
Publisher	ACM New York, NY, USA
ISBN	978-1-59593-593-9
Order Number	608073
Conference	CHIConference on Human Factors in Computing Systems
Paper Acceptance Rate 182 of 840 submissions, 22%
Overall Acceptance Rate 5,812 of 25,121 submissions, 23%
	
Year	Submitted	Accepted	Rate
CHI '82	165	75	45%
CHI '83	176	59	34%
CHI '85	170	35	21%
CHI '86	122	47	39%
CHI '87	166	46	28%
CHI '88	187	39	21%
CHI '89	199	54	27%
CHI '90	260	47	18%
CHI '91	240	56	23%
CHI '92	216	67	31%
CHI '93	330	62	19%
CHI '94	263	70	27%
CHI '95	228	66	29%
CHI '96	256	55	21%
CHI '97	234	55	24%
CHI '98	351	81	23%
CHI '99	312	78	25%
CHI '00	336	72	21%
CHI '01	352	69	20%
CHI '02	414	61	15%
CHI '03	468	75	16%
CHI '04	578	93	16%
CHI '05	372	93	25%
CHI '06	626	151	24%
CHI '07	840	182	22%
CHI '08	714	157	22%
CHI '09	1130	277	25%
CHI '10	1346	302	22%
CHI '11	1532	410	27%
CHI '12	1577	370	23%
CHI '13	1963	392	20%
CHI '14	2043	465	23%
CHI '15	2120	486	23%
CHI '16	2435	565	23%
CHI '17	2400	600	25%
Overall	25,121	5,812	23%

APPEARS IN
Interaction
top of pageREVIEWS

Reviews are not available for this item
 Computing Reviews logo 
Access critical reviews of computing literature.
Become a reviewer for Computing Reviews
 top of pageCOMMENTS
Be the first to comment To Post a comment please sign in or create a free Web account

top of pageTable of Contents
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems
Table of Contents

previousprevious proceeding |next proceeding next
SESSION: Faces & bodies in interaction
Anne Anderson
A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces
Nick Yee, Jeremy N Bailenson, Kathryn Rickertsen
Pages: 1-10
doi>10.1145/1240624.1240626
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questionnaire ratings, interviews) than when analyzing behavioral responses such as task performance and memory. Furthermore, the effects of adding an agent to an interface are larger than the effects of animating an agent to behave more realistically. However, the overall effect sizes were quite small (e.g., across studies, adding a face to an interface only explains approximately 2.5% of the variance in results). We discuss the implications for both designers building interfaces as well as social scientists designing experiments to evaluate those interfaces.

collapse
Improving recognition and characterization in groupware with rich embodiments
Tadeusz Stach, Carl Gutwin, David Pinelle, Pourang Irani
Pages: 11-20
doi>10.1145/1240624.1240627
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the feasibility of rich embodiment and their effects on group interaction, we carried out three studies. The first shows that users are able to recall and interpret a large set of variables that are graphically encoded on an embodiment. The second and third studies demonstrated rich embodiments in two groupware systems -- a multiplayer game and a drawing application -- and showed that the enhanced representations do improve recognition and characterization, and that they can enrich interaction in a variety of ways.

collapse
Coordinating joint activity in avatar-mediated interaction
Robert J. Moore, E. Cabell Hankinson Gathman, Nicolas Ducheneaut, Eric Nickell
Pages: 21-30
doi>10.1145/1240624.1240628
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game's standard awareness cues and the other with enhanced cues. We use conversation analysis to demonstrate interactional slippages caused by the absence of awareness cues, user practices that circumvent such limitations and ways in which enhanced cues can enable tighter coordination.

collapse
SECTION: Presentations
Web 2.0 and the Enterprise: The Business Impact of Modern Technological Approaches to Web Application Design
John Kolko, Jeff Veen, Jonathan Grubb
doi>10.1145/1240624.2180991
Full text: Mp3 Audio onlyMp3 Audio only
Faceted Metadata for Information Architecture and Search
Marti Hearst
doi>10.1145/1240624.2180994
Full text: Mp3 Part 1-Audio onlyMp3 Part 1-Audio only  Mp3 Part 2-Audio onlyMp3 Part 2-Audio only  Mp3 Part 3-Audio onlyMp3 Part 3-Audio only  Mp3 Part 4-Audio onlyMp3 Part 4-Audio only  Mp4 Part 1-VideoMp4 Part 1-Video  Mp4 Part 2-VideoMp4 Part 2-Video  Mp4 Part 3-VideoMp4 Part 3-Video  Mp4 Part 4-VideoMp4 Part 4-Video
Industrial Design: Challenges and Successes Towards an integrated Product Development Process
David Gilmore, Jeremy Ashley, Tucker Viemeister, Tim Wood
doi>10.1145/1240624.2180996
Full text: Mp3 Audio onlyMp3 Audio only
Wednesday CHI Madness
Patrick Baudisch
doi>10.1145/1240624.2180990
Full text: Mp3 Audio onlyMp3 Audio only
Monday CHI Madness
Partick Baudish
doi>10.1145/1240624.2180969
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Public Usability Laboratory
Ana Klasnja
doi>10.1145/1240624.2180965
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
From Mice to Men - 24 Years of Evaluation in CHI
Louise Barkhuus, Jennifer A. Rode
doi>10.1145/1240624.2180963
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Welcome to CHI
Mary Beth Rosson
doi>10.1145/1240624.2180959
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Introduction
Steven Wall, Ilona Posner
doi>10.1145/1240624.2181021
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Thanks to our sponsors
Mary Beth Rosson
doi>10.1145/1240624.2181020
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Past, Present, and Future of HCC Education: What We Teach, How We Teach
Jim Foley
doi>10.1145/1240624.2180988
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Tuesday CHI Madness
Gonzalo Ramos
doi>10.1145/1240624.2180967
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
ACM welcome
Stu Feldman
doi>10.1145/1240624.2180960
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Avoiding We Can't Change THAT!: An Introduction to Usability & Software Architecture
Bonnie E. John, Len Bass, Elspeth Golden
doi>10.1145/1240624.2180997
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
CHI 2008 Preview
Mary Czerwinski, Desney Tan, Arnie Lund, Ben Shneiderman
doi>10.1145/1240624.2181002
Full text: Mp3 Audio onlyMp3 Audio only
Introduction to CSCW - 1
Jim Herbsleb, Gary Olson
doi>10.1145/1240624.2180955
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Introduction to HCI - 1
Keith Butler, Rob Jacobs, David Kieras
doi>10.1145/1240624.2180956
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Opening Plenary Talk
Bill Moggridge
doi>10.1145/1240624.2180961
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Introduction to CSCW - 2
Jim Herbsleb, Gary Olson
doi>10.1145/1240624.2180958
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
The Evolution of Evaluation
Joseph 'Jofish' Kaye, Phoebe Sengers
doi>10.1145/1240624.2180962
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Avoiding We Can't Change That Either!: Usability Supporting Architectural Patterns
Bonnie E. John, Elspeth Golden
doi>10.1145/1240624.2206886
Full text: Mp3 Part 1-Audio OnlyMp3 Part 1-Audio Only  Mp3 Part 2-Audio OnlyMp3 Part 2-Audio Only  Mp4 Part 1-VideoMp4 Part 1-Video  Mp4 Part 2-VideoMp4 Part 2-Video
Program addenda
doi>10.1145/1240624.2180968
Full text: Mp3 Audio onlyMp3 Audio only
Using Computing Technologies to Face the Challenges of Autism
Gregory D. Abowd
doi>10.1145/1240624.2181000
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
CHI Madness: Summary of other entries
Patrick Baudisch, Gonzalo Ramos
doi>10.1145/1240624.2180995
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
CHI 2007 Welcome
Dennis Wixon, Mary Beth Rosson, David Gilmore
doi>10.1145/1240624.2181033
Full text: Mp3 Audio onlyMp3 Audio only
Thursday CHI Madness
Gonzalo Ramos
doi>10.1145/1240624.2180999
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
The mobile as a post Industrial platform for socio-economic development
Niti Bhan
doi>10.1145/1240624.2181001
Full text: Mp3 Audio onlyMp3 Audio only
Introduction to HCI - 2
Keith Butler, Rob Jacobs, David Kieras
doi>10.1145/1240624.2180957
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Make Evaluation Poverty History
Gilbert Cockton
doi>10.1145/1240624.2180964
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Doing HCI Differently -- Stories from the Developing World
Gary Marsden
doi>10.1145/1240624.2180966
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
Along the Path of Pervasive Computing: Selected Works in GUI and TUI Design
Bill Lucas, Hiroshi Ishii, Jake Kolojejchick, Peter Lucas, David Rose
doi>10.1145/1240624.2180987
Full text: Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video
SESSION: Attention & interruption
Brian Bailey
How it works: a field study of non-technical users interacting with an intelligent system
Joe Tullio, Anind K. Dey, Jason Chalecki, James Fogarty
Pages: 31-40
doi>10.1145/1240624.1240630
Full text: PDFPDF

In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount some of their initial misconceptions about what information the system used for reasoning about interruptibility. However, the overarching structures of their mental models stayed relatively stable over the course of the study. Lastly, we found that participants were able to give lay descriptions attributing simple machine learning concepts to the system despite their lack of technical knowledge. Our findings suggest an appropriate level of feedback for user interfaces of intelligent systems, provide a baseline level of complexity for user understanding, and highlight the challenges of making users aware of sensed inputs for such systems.

collapse
Matching attentional draw with utility in interruption
Jennifer Gluck, Andrea Bunt, Joanna McGrenere
Pages: 41-50
doi>10.1145/1240624.1240631
Full text: PDFPDF

This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different levels of utility. Results indicate that the matching strategy decreases annoyance and increases perception of benefit compared to a strategy that uses the same signal regardless of interruption utility, with no significant impact on workload or performance. Design implications arising from the second experiment as well as recommendations for future work are discussed.

collapse
Biases in human estimation of interruptibility: effects and implications for practice
Daniel Avrahami, James Fogarty, Scott E. Hudson
Pages: 50-60
doi>10.1145/1240624.1240632
Full text: PDFPDF

People have developed a variety of conventions for negotiating face to face interruptions. The physical distribution of teams, however, together with the use of computer mediated communication and awareness systems, fundamentally alters what information is available to a person considering an interruption of a remote collaborator. This paper presents a detailed comparison between self-reports of interruptibility, collected from participants over extended periods in their actual work environment, and estimates of this interruptibility, provided by a second set of participants based on audio and video recordings. Our results identify activities and environmental cues that affect participants' ability to correctly estimate interruptibility. We show, for example, that a closed office door had a significant effect on observers' estimation of interruptibility, but did not have an effect on participants' reports of their own interruptibility. We discuss our findings and their importance for successful design of computer-mediated communication and awareness systems.

collapse
SESSION: Capturing life experiences
Sara Kiesler
Understanding videowork
David Kirk, Abigail Sellen, Richard Harper, Ken Wood
Pages: 61-70
doi>10.1145/1240624.1240634
Full text: PDFPDF

In this paper we elucidate the patterns of behavior of home movie makers through a study of 12 families and a separate focus group of 7 teenagers. Analogous to a similar study of photowork [13], the goal is to provide a deeper understanding of what people currently do with video technologies, balancing the preponderence of techno-centric work in the area with appropriate user-centric insight. From our analysis, we derive a videowork lifecycle to frame the practices users engage in when working with video technologies in the home, and uncover two broad types of video usage therein. This has implications for how we conceive of and devise tools to support these practices, as we discuss.

collapse
Software or wetware?: discovering when and why people use digital prosthetic memory
Vaiva Kalnikaité, Steve Whittaker
Pages: 71-80
doi>10.1145/1240624.1240635
Full text: PDFPDF

Our lives are full of memorable and important moments, as well as important items of information. The last few years have seen the proliferation of digital devices intended to support prosthetic memory (PM), to help users recall experiences, conversations and retrieve personal information. We nevertheless have little systematic understanding of when and why people might use such devices, in preference to their own organic memory (OM). Although OM is fallible, it may be more efficient than accessing information from a complex PM device. We report a controlled lab study which investigates when and why people use PM and OM. We found that PM use depended on users' evaluation of the quality of their OM, as well as PM device properties. In particular, we found that users trade-off Accuracy and Efficiency, preferring rapid access to potentially inaccurate information over laborious access to accurate information. We discuss the implications of these results for future PM design and theory. Rather than replacing OM, future PM designs need to focus on allowing OM and PM to work in synergy.

collapse
Do life-logging technologies support memory for the past?: an experimental study using sensecam
Abigail J. Sellen, Andrew Fogg, Mike Aitken, Steve Hodges, Carsten Rother, Ken Wood
Pages: 81-90
doi>10.1145/1240624.1240636
Full text: PDFPDF

We report on the results of a study using SenseCam, a "life-logging" technology in the form of a wearable camera, which aims to capture data about everyday life in order to support people's memory for past, personal events. We find evidence that SenseCam images do facilitate people's ability to connect to their past, but that images do this in different ways. We make a distinction between "remembering" the past, and "knowing" about it, and provide evidence that SenseCam images work differently over time in these capacities. We also compare the efficacy of user-captured images with automatically captured images and discuss the implications of these findings and others for how we conceive of and make claims about life-logging technologies.

collapse
SESSION: Large displays
Mary Czerwinski
An exploratory study of input configuration and group process in a negotiation task using a large display
Jeremy P. Birnholtz, Tovi Grossman, Clarissa Mak, Ravin Balakrishnan
Pages: 91-100
doi>10.1145/1240624.1240638
Full text: PDFPDF

This paper reports on an exploratory study of the effects of input configuration on group behavior and performance in a collaborative task performed by a collocated group using a large display. Twelve groups completed a mixed-motive negotiation task under two conditions: a single, shared mouse and one mouse per person. Results suggest that the multiple mouse condition allowed for more parallel work, but the quality of discussion was higher in the single mouse condition. Moreover, participants were more likely to act in their own best interest in the multiple mouse condition.

collapse
Beyond visual acuity: the perceptual scalability of information visualizations for large displays
Beth Yost, Yonca Haciahmetoglu, Chris North
Pages: 101-110
doi>10.1145/1240624.1240639
Full text: PDFPDF

The scalability of information visualizations has typically been limited by the number of available display pixels. As displays become larger, the scalability limit may shift away from the number of pixels and toward human perceptual abilities. This work explores the effect of using large, high resolution displays to scale up information visualizations beyond potential visual acuity limitations. Displays that are beyond visual acuity require physical navigation to see all of the pixels. Participants performed various information visualization tasks using display sizes with a sufficient number of pixels to be within, equal to, or beyond visual acuity. Results showed that performance on most tasks was more efficient and sometimes more accurate because of the additional data that could be displayed, despite the physical navigation that was required. Visualization design issues on large displays are also discussed.

collapse
White rooms and morphing don't mix: setting and the evaluation of visualization techniques
Derek F. Reilly, Kori M. Inkpen
Pages: 111-120
doi>10.1145/1240624.1240640
Full text: PDFPDF

The results presented in this paper illustrate how a specific map visualization technique is sensitive to setting: a comparative evaluation of the technique gives conflicting results depending on where it takes place. While prior research has explored the impact of factors other than basic visual perception on visualization techniques, relatively little attention has been directed toward the physical setting in which the technique is used. We present results from a study involving 120 participants, comparing the effectiveness of two different geovisualization techniques in promoting recall of map layout. Recall was shown to be sensitive to setting, such that one technique in particular was more effective in a noisy public space than in a controlled, 'white-room' environment. The results have implications for the validation and measurement of information visualization techniques as a whole, and in particular for those employing motion as a communicative attribute.

collapse
SESSION: Shake, rattle and roll: new forms of input and output
Lars Erik Holmquist
Shoogle: excitatory multimodal interaction on mobile devices
John Williamson, Roderick Murray-Smith, Stephen Hughes
Pages: 121-124
doi>10.1145/1240624.1240642
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Shoogle is a novel, intuitive interface for sensing data withina mobile device, such as presence and properties of textmessages or remaining resources. It is based around activeexploration: devices are shaken, revealing the contents rattlingaround "inside". Vibrotactile display and realistic impactsonification create a compelling system. Inertial sensingis used for completely eyes-free, single-handed interactionthat is entirely natural. Prototypes are described runningboth on a PDA and on a mobile phone with a wireless sensorpack. Scenarios of use are explored where active sensing ismore appropriate than the dominant alert paradigm.

collapse
SESSION: Ubicomp tools
Beverly Harrison
Momento: support for situated ubicomp experimentation
Scott Carter, Jennifer Mankoff, Jeffrey Heer
Pages: 125-134
doi>10.1145/1240624.1240644
Full text: PDFPDF

We present the iterative design of Momento, a tool that providesintegrated support for situated evaluation of ubiquitouscomputing applications. We derived requirements for Momento from a user-centered design process that includedinterviews, observations and field studies of early versionsof the tool. Motivated by our findings, Momento supportsremote testing of ubicomp applications, helps with participantadoption and retention by minimizing the need for newhardware, and supports mid-to-long term studies to addressinfrequently occurring data. Also, Momento can gather logdata, experience sampling, diary, and other qualitative data.

collapse
Toolkit support for developing and deploying sensor-based statistical models of human situations
James Fogarty, Scott E. Hudson
Pages: 135-144
doi>10.1145/1240624.1240645
Full text: PDFPDF

Sensor based statistical models promise to support a variety of advances in human computer interaction, but building applications that use them is currently difficult and potential advances go unexplored. We present Subtle, a toolkit that removes some of the obstacles to developing and deploying applications using sensor based statistical models of human situations. Subtle provides an appropriate and extensible sensing library, continuous learning of personalized models, fully automated high level feature generation, and support for using learned models in deployed applications. By removing obstacles to developing and deploying sensor based statistical models, Subtle makes it easier to explore the design space surrounding sensor based statistical models of human situations. Subtle thus helps to move the focus of human computer interaction research onto applications and datasets, instead of the difficulties of developing and deploying sensor based statistical models.

collapse
Authoring sensor-based interactions by demonstration with direct manipulation and pattern recognition
Björn Hartmann, Leith Abdulla, Manas Mittal, Scott R. Klemmer
Pages: 145-154
doi>10.1145/1240624.1240646
Full text: PDFPDF

Sensors are becoming increasingly important in interaction design. Authoring a sensor-based interaction comprises three steps: choosing and connecting the appropriate hardware, creating application logic, and specifying the relationship between sensor values and application logic. Recent research has successfully addressed the first two issues. However, linking sensor input data to application logic remains an exercise in patience and trial-and-error testing for most designers. This paper introduces techniques for authoring sensor-based interactions by demonstration. A combination of direct manipulation and pattern recognition techniques enables designers to control how demonstrated examples are generalized to interaction rules. This approach emphasizes design exploration by enabling very rapid iterative demonstrate-edit-review cycles. This paper describes the manifestation of these techniques in a design tool, Exemplar, and presents evaluations through a first-use lab study and a theoretical analysis using the Cognitive Dimensions of Notation framework.

collapse
SESSION: Mobile interaction
Kori Inkpen
Questions not answers: a novel mobile search technique
Matt Jones, George Buchanan, Richard Harper, Pierre-Louis Xech
Pages: 155-158
doi>10.1145/1240624.1240648
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Mobile search is becoming an increasingly important user activity. In this paper, instead of investigating the most efficient and effective ways of providing search results, the answers, we consider the value of giving access to previous queries, the questions, relating to a user's location. By exposing what other people have searched for, the aim is to provide useful insights into a location's character. To consider the value of the approach we deployed two mobile probes in a large-scale field study involving 391 participants. Our experiences suggest that presenting users with other people's in situ queries influences their information seeking interactions positively.

collapse
Tactile feedback for mobile interactions
Stephen Brewster, Faraz Chohan, Lorna Brown
Pages: 159-162
doi>10.1145/1240624.1240649
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

We present a study investigating the use of vibrotactile feedback for touch-screen keyboards on PDAs. Such key-boards are hard to use when mobile as keys are very small. We conducted a laboratory study comparing standard but-tons to ones with tactile feedback added. Results showed that with tactile feedback users entered significantly more text, made fewer errors and corrected more of the errors they did make. We ran the study again with users seated on an underground train to see if the positive effects trans-ferred to realistic use. There were fewer beneficial effects, with only the number of errors corrected significantly im-proved by the tactile feedback. However, we found strong subjective feedback in favour of the tactile display. The results suggest that tactile feedback has a key role to play in improving interactions with touch screens.

collapse
Revisiting and validating a model of two-thumb text entry
Edward Clarkson, Kent Lyons, James Clawson, Thad Starner
Pages: 163-166
doi>10.1145/1240624.1240650
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

MacKenzie and Soukoreff have previously introduced a Fitts' Law-based performance model of expert two-thumb text entry on mini-QWERTY keyboards [4]. In this work we validate the original model using results from a longitudinal study of mini-QWERTY keyboards, and update the model to account for observed inter-key time data.

collapse
"Jump and refine" for rapid pointing on mobile phones
Martin Hachet, Joachim Pouderoux, Florence Tyndiuk, Pascal Guitton
Pages: 167-170
doi>10.1145/1240624.1240651
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Standard input devices for mobile phones are directional keys and discrete thumb-joysticks. These devices are dedicated to the discrete GUIs of the phones (eg. scroll lists and small icons arrays). Today, new mobile applications are arising and require adapted interfaces. In particular, the widespread of 3D applications will be favored if users can efficiently point on any part of thescreen. In this paper, we propose a new interaction technique called Jump and Refine for selection tasks on mobile phones. This technique is based on two levels of cursor displacement in order to reduce the number of keystrokes. The first level allows fast movements into an underlying grid. The second one can be used for accurate positioning into the selected area. We present a user study which shows that using a first coarse jump level decreases the selection completion times. The study also shows that the technique is widely accepted by the users. Finally, we discuss the optimal grid sizes.

collapse
SESSION: Politics & activism
Jodi Forlizzi
Usability of voting systems: baseline data for paper, punch cards, and lever machines
Michael D. Byrne, Kristen K. Greene, Sarah P. Everett
Pages: 171-180
doi>10.1145/1240624.1240653
Full text: PDFPDF

In the United States, computer-based voting machines are rapidly replacing other older technologies. While there is potential for this to be a usability improvement, particularly in terms of accessibility, the only way it is possible to know if usability has improved is to have baseline data on the usability of traditional technologies. We report an experiment assessing the usability of punch cards, lever machines, and two forms of paper ballot. There were no differences in ballot completion time between the four methods, but there were substantial effects on error rate, with the paper ballots superior to the other methods as well as an interaction with age of voters. Subjective usability was assessed with the System Usability Scale and showed a slight advantage for bubble-style paper ballots. Overall, paper ballots were found to be particularly usable, which raises important technological and policy issues.

collapse
A game design methodology to incorporate social activist themes
Mary Flanagan, Helen Nissenbaum
Pages: 181-190
doi>10.1145/1240624.1240654
Full text: PDFPDF

Can a set of articulated and tested methodologies be created whose endpoint is the reliable capacity for taking activist social themes into account? In this paper we explore a variety of educational and activist game approaches, and look specifically at the themes emerging from recent projects involving game design for young women. We articulate here design practices in a methodology, Values at Play (VAP), that could be used in the creation of games as well as the teaching of game design.

collapse
SESSION: Navigation & interaction
Patrick Baudisch
Move to improve: promoting physical navigation to increase user performance with large displays
Robert Ball, Chris North, Doug A. Bowman
Pages: 191-200
doi>10.1145/1240624.1240656
Full text: PDFPDF

In navigating large information spaces, previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying). However, there is also indication of users preferring or settling into the less efficient virtual navigation. We present a study that examines these issues in the context of large, high resolution displays. The study identifies specific relationships between display size, amount of physical and virtual navigation, and user task performance. Increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance. Analyzing the differences between this study and previous results helps to identify design factors that afford and promote the use of physical navigation in the user interface.

collapse
Copy-and-paste between overlapping windows
Olivier Chapuis, Nicolas Roussel
Pages: 201-210
doi>10.1145/1240624.1240657
Full text: PDFPDF

Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.

collapse
Consistency, multiple monitors, and multiple windows
Dugald Ralph Hutchings, John Stasko
Pages: 211-214
doi>10.1145/1240624.1240658
Full text: PDFPDF

We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management.

collapse
How pairs interact over a multimodal digital table
Edward Tse, Chia Shen, Saul Greenberg, Clifton Forlines
Pages: 215-218
doi>10.1145/1240624.1240659
Full text: PDFPDF

Co-located collaborators often work over physical tabletops using combinations of expressive hand gestures and verbal utterances. This paper provides the first observations of how pairs of people communicated and interacted in a multimodal digital table environment built atop existing single user applications. We contribute to the understanding of these environments in two ways. First, we saw that speech and gesture commands served double duty as both commands to the computer, and as implicit communication to others. Second, in spite of limitations imposed by the underlying single-user application, people were able to work together simultaneously, and they performed interleaving acts: the graceful mixing of inter-person speech and gesture actions as commands to the system. This work contributes to the intricate understanding of multi-user multimodal digital table interaction.

collapse
SESSION: Medical
David McDonald
An observational study on information flow during nurses' shift change
Charlotte Tang, Sheelagh Carpendale
Pages: 219-228
doi>10.1145/1240624.1240661
Full text: PDFPDF

We present an observational study that was conducted to guide the design and development of technologies to support information flow during nurses' shift change in a hospital ward. Our goal is to find out how the complex information sharing processes during nurses' brief shift change unfold in a hospital setting. Our study shows the multitude of information media that nurses access during the parallel processes of information assembly and disassembly: digital, paper-based, displayed and verbal media. An initial analysis reveals how the common information spaces, where information media are positioned and accessible by all participants, are actively used and how they interact with the personal information spaces ephemerally constructed by the participants. Several types of information are consistently transposed from the common information spaces to the personal information space including: demographics, historical data, reminders and to-dos, alerts, prompts, scheduling and reporting information. Information types are often enhanced with a variety of visual cues to help nurses carry out their tasks.

collapse
Medical sensemaking with entity workspace
Dorrit Billman, Eric A. Bier
Pages: 229-232
doi>10.1145/1240624.1240662
Full text: PDFPDF

Knowledge workers making sense of a topic divide their time among activities including searching for information, reading, and taking notes. We have built a software system that supports and integrates these activities. To test its effectiveness, we conducted a study where subjects used it to perform medical question-answering tasks. Initial results indicate that subjects could use the system, but that the nature of this use depended on the subject's overall question-answering strategy. Two dominant strategies emerged that we call the Reader and Searcher strategies.

collapse
SESSION: Task & attention
Anthony Hornof
A cognitive constraint model of dual-task trade-offs in a highly dynamic driving task
Duncan P. Brumby, Andrew Howes, Dario D. Salvucci
Pages: 233-242
doi>10.1145/1240624.1240664
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

The paper describes an approach to modeling the strategic variations in performing secondary tasks while driving. In contrast to previous efforts that are based on simulation of a cognitive architecture interacting with a task environment, we take an approach that develops a cognitive constraint model of the interaction between the driver and the task environment in order to make inferences about dual-task performance. Analyses of driving performance data reveal that a set of simple equations can be used to accurately model changes in the lateral position of the vehicle within the lane. The model quantifies how the vehicle's deviation from lane center increases during periods of inattention, and how the vehicle returns to lane center during periods of active steering. We demonstrate the benefits of the approach by modeling the dialing of a cellular phone while driving, where drivers balance the speed in performing the dial task with accuracy (or safety) in keeping the vehicle centered in the roadway. In particular, we show how understanding, rather than simulating, the constraints imposed by the task environment can help to explain the costs and benefits of a range of strategies for interleaving dialing and steering. We show how particular strategies are sensitive to a combination of internal constraints (including switch costs) and the trade-off between the amount of time allocated to secondary task and the risk of extreme lane deviation.

collapse
iPod distraction: effects of portable music-player use on driver performance
Dario D. Salvucci, Daniel Markley, Mark Zuber, Duncan P. Brumby
Pages: 243-250
doi>10.1145/1240624.1240665
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Portable music players such as Apple's iPod have become ubiquitous in many environments, but one environment in particular has elicited new safety concerns and challenges -- in-vehicle use while driving. We present the first study of portable music-player interaction while driving, examining the effects of iPod interaction by drivers navigating a typical roadway in a driving simulator. Results showed that selecting media on the iPod had a significant effect on driver performance as measured by lateral deviation from lane center; the effect was comparable to previously reported effects of dialing a cellular phone. In addition, selecting media and watching videos had a significant effect on car-following speed, resulting in speed reductions that presumably compensated for impaired lateral performance. Given that iPod interaction has become increasingly common while driving, these results serve as a first step toward understanding the potential effects of portable music-player interaction on driver behavior and performance.

collapse
InkSeine: In Situ search for active note taking
Ken Hinckley, Shengdong Zhao, Raman Sarin, Patrick Baudisch, Edward Cutrell, Michael Shilman, Desney Tan
Pages: 251-260
doi>10.1145/1240624.1240666
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Using a notebook to sketch designs, reflect on a topic, or capture and extend creative ideas are examples of active note taking tasks. Optimal experience for such tasks demands concentration without interruption. Yet active note taking may also require reference documents or emails from team members. InkSeine is a Tablet PC application that supports active note taking by coupling a pen-and-ink interface with an in situ search facility that flows directly from a user's ink notes (Fig. 1). InkSeine integrates four key concepts: it leverages preexisting ink to initiate a search; it provides tight coupling of search queries with application content; it persists search queries as first class objects that can be commingled with ink notes; and it enables a quick and flexible workflow where the user may freely interleave inking, searching, and gathering content. InkSeine offers these capabilities in an interface that is tailored to the unique demands of pen input, and that maintains the primacy of inking above all other tasks.

collapse
SESSION: Expert/novice
Paul Aoki
Sharing a single expert among multiple partners
Jeffrey Wong, Lui Min Oh, Jiazhi Ou, Carolyn P. Rosé, Jie Yang, Susan R. Fussell
Pages: 261-270
doi>10.1145/1240624.1240668
Full text: PDFPDF

Expertise to assist people on complex tasks is often in short supply. One solution to this problem is to design systems that allow remote experts to help multiple people in simultaneously. As a first step towards building such a system, we studied experts' attention and communication as they assisted two novices at the same time in a co-located setting. We compared simultaneous instruction when the novices are being instructed to do the same task or different tasks. Using machine learning, we attempted to identify speech markers of upcoming attention shifts that could serve as input to a remote assistance system.

collapse
Dynamic detection of novice vs. skilled use without a task model
Amy Hurst, Scott E. Hudson, Jennifer Mankoff
Pages: 271-280
doi>10.1145/1240624.1240669
Full text: PDFPDF

If applications were able to detect a user's expertise, then software could automatically adapt to better match exper-tise. Detecting expertise is difficult because a user's skill changes as the user interacts with an application and differs across applications. This means that expertise must be sensed dynamically, continuously, and unobtrusively so as not to burden the user. We present an approach to this prob-lem that can operate without a task model based on low-level mouse and menu data which can typically be sensed across applications at the operating systems level. We have implemented and trained a classifier that can detect "nov-ice" or "skilled" use of an image editing program, the GNU Image Manipulation Program (GIMP), at 91% accuracy, and tested it against real use. In particular, we developed and tested a prototype application that gives the user dy-namic application information that differs depending on her performance.

collapse
Approaches to web search and navigation for older computer novices
Anna Dickinson, Michael J. Smith, John L. Arnott, Alan F. Newell, Robin L. Hill
Pages: 281-290
doi>10.1145/1240624.1240670
Full text: PDFPDF

A proof of concept web search and navigation system was developed for older people for whom the Internet is seen as an alien territory. A joint industry/academia team deployed User Sensitive Inclusive Design principles, focusing on the usability of the interface for this user group. The search and navigation system that was developed was significantly preferred by the user group to that provided by a standard commercial (Internet Service Provider) system; it scored highly for ease of use and the participants reported increased confidence in their ability to master the Internet. Recorded quantitative measures showed fewer task errors. The outcome of the development was a successful "proof of concept" search and navigation system for older novice computer users together with approaches to design and development for those who wish to design for this user group.

collapse
SESSION: Mobile applications
Scott McCrickard
Designing a mobile user interface for automated species identification
Sean Michael White, Dominic Marino, Steven Feiner
Pages: 291-294
doi>10.1145/1240624.1240672
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Biological research in the field is constrained by the speed and difficulty of species determination, as well as by access to relevant information about the species encountered. However, recent work on vision-based algorithms raises the promise of rapid botanical species identification. The potential for mobile vision-based identification provides opportunities for new user interface techniques. To explore these issues, we present LeafView, a Tablet-PC-based user interface for an electronic field guide that supports automated identification of botanical species in the field. We describe a user interface design based on an ethnographic study of botanists, field tests of working prototypes by botanists at the Smithsonian Institution on Plummers Island, Maryland, and observations at an internal exhibition at the Smithsonian at which other staff members tried the prototypes. We present functionality specific to mobile identification and collection in the electronic field guide and use this to motivate discussion of mobile identification in general.

collapse
BrickRoad: a light-weight tool for spontaneous design of location-enhanced applications
Alan L. Liu, Yang Li
Pages: 295-298
doi>10.1145/1240624.1240673
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

It is difficult to design and test location-enhancedapplications. A large part of this difficulty is due to the added complexity of supporting location. Wizard of Oz (WOz) has become an effective technique for the early stage design of location-enhanced applications because it allows designers to test an application prototype bysimulating nonexistent components such as location sensing. However, existing WOz tools 1) require nontrivial effort from designers to specify how a prototype should behave before it can be tested with end users, and 2)support only limited control over application behavior during a test. BrickRoad is a WOz tool for spontaneousdesign of location-enhanced applications. It lowers the threshold to acquiring user feedback and exploring a design space. With BrickRoad, a designer does not need to specify any interaction logic and can experiment on-the-fly with different designs during testing. BrickRoad is a valuable complement to existing tool support for the early stage design of location-enhanced applications.

collapse
Psychophysical elements of wearability
Lucy E. Dunne, Barry Smyth
Pages: 299-302
doi>10.1145/1240624.1240674
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Wearable technology presents a wealth of new HCI issues. In particular, this paper addresses the impact of the physical interaction between the user's body and the device's physical form on the user's mental representation of self and cognitive abilities, a blend of HCI and ergonomics that is unique to wearable computing. We explore the human sensory mechanisms that facilitate perception of worn objects and the elements of sensation that influence the comfort of worn objects, and discuss the psychological elements that may cause worn objects to be forgotten or detected, wearable or not. We discuss the implications of un-wearability on attention and cognitive capability.

collapse
The tilt cursor: enhancing stimulus-response compatibility by providing 3d orientation cue of pen
Feng Tian, Xiang Ao, Hongan Wang, Vidya Setlur, Guozhong Dai
Pages: 303-306
doi>10.1145/1240624.1240675
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

In order to improve stimulus-response compatibility of touchpad in pen-based user interface, we present the tilt cursor, i.e. a cursor dynamically reshapes itself to providing the 3D orientation cue of pen. We also present two experiments that evaluate the tilt cursor's performance in circular menu selection and specific marking menu selection tasks. Results show that in a specific marking menu selection task, the tilt cursor significantly outperforms the shape-fixed arrow cursor and the live cursor [4]. In addition, results show that by using the tilt cursor, the response latencies for adjusting drawing directions are smaller than that by using the other two kinds of cursors.

collapse
How younger and older adults master the usage of hyperlinks in small screen devices
Martina Ziefle, Ulrik Schroeder, Judith Strenk, Thomas Michel
Pages: 307-316
doi>10.1145/1240624.1240676
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

In this paper we describe an experiment, in which we examined older and younger adults when interacting with a simulated PDA (personal digital assistant). Independent variables were users' age (young vs. older) and device interface (hyperlink vs. no hyperlink). Dependent variables were the effectiveness and efficiency of menu navigation. To understand how user characteristics influence performance, spatial ability, verbal memory, computer expertise and technical self-confidence were determined. Technology experienced young and older adults (benchmark testing) took part. They had to solve four tasks either with hyperlink interface or without hyperlinks in the interface. The method to collect, to automatically analyze and to structure the data according to interaction sequences and presumed user intentions is a novel approach supported by the open source software tool Clever [12]. The tool is briefly described; more details can be found in [23]. Results revealed that hyperlink interfaces showed overall higher effectiveness. However, the impact of hyperlinks for efficiency was age-related. Younger adults strongly benefit from having hyperlinks. The contrary was the case for older adults, who showed higher menu disorientation when using hyperlinks.

collapse
SESSION: Navigation
Robert Jacob
Modeling steering within above-the-surface interaction layers
Raghavendra S. Kattinakere, Tovi Grossman, Sriram Subramanian
Pages: 317-326
doi>10.1145/1240624.1240678
Full text: PDFPDF

Interaction techniques that utilize the space above the display surface to extend the functionalities of digitized surfaces continue to emerge. In such techniques, movements are constrained by the bounds of a layer. In addition, constraints imposed on the direction of movement within the layer may be present. Despite the presence of such techniques, there is limited understanding of human capabilities for performing the required steering task. In this paper we study and model user performance when steering through constrained and unconstrained paths in above-the-surface layers. Through a series of experiments we validate the derivation and applicability of our proposed models.

collapse
Quantifying degree of goal directedness in document navigation: application to the evaluation of the perspective-drag technique
Yves Guiard, Yangzhou Du, Olivier Chapuis
Pages: 327-336
doi>10.1145/1240624.1240679
Full text: PDFPDF

This article pursues a two-fold goal. First we introduce degree of goal directedness (DGD), a novel quantitative dimension for the taxonomy of navigation tasks in general. As an attempt to operationalize the DGD concept in the context of electronic documents navigation, we introduce the serial target-acquisition (STA) experimental paradigm. We suggest that DGD and the STA paradigm may usefully enrich the conceptual toolkit of HCI research for the evaluation of navigation techniques. Our second goal is to illustrate the utility of the DGD concept by showing with a concrete example, Perspective Drag, the refinement it allows in evaluating navigation techniques. We report data obtained from two experiments with the STA paradigm that cast light on what Perspective Drag is specifically good for: it is particularly suitable in realistic task contexts where navigation is less than 100% directed by its terminal goal, that is, where the user wants not only to reach a particular item but also to pick up information from the document during document traversal.

collapse
PageLinker: integrating contextual bookmarks within a browser
Aurélien Tabard, Wendy Mackay, Nicolas Roussel, Catherine Letondal
Pages: 337-346
doi>10.1145/1240624.1240680
Full text: PDFPDF

PageLinker is a browser extension that allows to contextualise navigation by linking web pages together and to navigate through a network of related web pages without prior planning. The design is based on extensive interviews with biologists, which highlighted their difficulties finding previously visited web pages. They found current browser tools inadequate, resulting in poorly organised bookmarks and rarely used history lists. In a four-week controlled field experiment, PageLinker significantly reduced time, page loads and mouse clicks. By presenting links in context, PageLinker facilitates web page revisitation, is less prone to bookmark overload and is highly robust to change.

collapse
SESSION: Photo sharing
Jakob Bardram
Give and take: a study of consumer photo-sharing culture and practice
Andrew D. Miller, W. Keith Edwards
Pages: 347-356
doi>10.1145/1240624.1240682
Full text: PDFPDF

In this paper, we present initial findings from the study of a digital photo-sharing website: Flickr.com. In particular, we argue that Flickr.com appears to support-for some people-a different set of photography practices, socialization styles, and perspectives on privacy that are unlike those described in previous research on consumer and amateur photographers. Further, through our examination of digital photographers' photowork activities-organizing, finding, sharing and receiving-we suggest that privacy concerns and lack of integration with existing communication channels have the potential to prevent the 'Kodak Culture' from fully adopting current photo-sharing solutions.

collapse
Over-exposed?: privacy patterns and considerations in online and mobile photo sharing
Shane Ahern, Dean Eckles, Nathaniel S. Good, Simon King, Mor Naaman, Rahul Nair
Pages: 357-366
doi>10.1145/1240624.1240683
Full text: PDFPDF

As sharing personal media online becomes easier and widely spread, new privacy concerns emerge - especially when the persistent nature of the media and associated context reveals details about the physical and social context in which the media items were created. In a first-of-its-kind study, we use context-aware camerephone devices to examine privacy decisions in mobile and online photo sharing. Through data analysis on a corpus of privacy decisions and associated context data from a real-world system, we identify relationships between location of photo capture and photo privacy settings. Our data analysis leads to further questions which we investigate through a set of interviews with 15 users. The interviews reveal common themes in privacy considerations: security, social disclosure, identity and convenience. Finally, we highlight several implications and opportunities for design of media sharing applications, including using past privacy patterns to prevent oversights and errors.

collapse
EasyAlbum: an interactive photo annotation system based on face clustering and re-ranking
Jingyu Cui, Fang Wen, Rong Xiao, Yuandong Tian, Xiaoou Tang
Pages: 367-376
doi>10.1145/1240624.1240684
Full text: PDFPDF

Digital photo management is becoming indispensable for the explosively growing family photo albums due to the rapid popularization of digital cameras and mobile phone cameras. In an effective photo management system photo annotation is the most challenging task. In this paper, we develop several innovative interaction techniques for semi-automatic photo annotation. Compared with traditional annotation systems, our approach provides the following new features: "cluster annotation" puts similar faces or photos with similar scene together, and enables user label them in one operation; "contextual re-ranking" boosts the labeling productivity by guessing the user intention; "ad hoc annotation" allows user label photos while they are browsing or searching, and improves system performance progressively through learning propagation. Our results show that these technologies provide a more user friendly interface for the annotation of person name, location, and event, and thus substantially improve the annotation performance especially for a large photo album.

collapse
SESSION: Empirical studies of web interaction
Joanna McGrenere
An exploration of web-based monitoring: implications for design
Melanie Kellar, Carolyn Watters, Kori M. Inkpen
Pages: 377-386
doi>10.1145/1240624.1240686
Full text: PDFPDF

Monitoring occurs when users return to previously viewed web pages to view new or updated information. While tools exist to support web-based monitoring, we know little about the monitoring activities users engage in and the nature of the support needed. We have conducted 40 semi-structured interviews in order to better understand the types of information users monitor and the characteristics of different monitoring activities. Using the data collected during the interviews, we characterized monitoring as an activity within six web information tasks: Browsing, Communications, Fact Finding, Information Gathering, Maintenance, and Transactions. The results of our study have been used to provide general, as well as task specific, recommendations for the design of monitoring tools.

collapse
Investigating attractiveness in web user interfaces
Jan Hartmann, Alistair Sutcliffe, Antonella De Angeli
Pages: 387-396
doi>10.1145/1240624.1240687
Full text: PDFPDF

A theoretical framework for assessing the attractiveness of websites based on Adaptive Decision Making theory is introduced. The framework was developed into a questionnaire and used to evaluate three websites which shared the same brand and topic but differed in aesthetic design. The DSchool site was favoured overall and was best for aesthetics and usability. The subjective ratings of the sites were in conflict with the subject-reported comments on usability problems. Subjects were given two scenarios for their preference. They changed their preference from the DSchool to the HCI Group's site for the more serious (PhD study) scenario; however, design background students remained loyal to the DSchool. The implications of framing and halo effects on users' judgement of aesthetics are discussed.

collapse
The relationship between accessibility and usability of websites
Helen Petrie, Omar Kheir
Pages: 397-406
doi>10.1145/1240624.1240688
Full text: PDFPDF

Accessibility and usability are well established concepts for user interfaces and websites. Usability is precisely defined, but there are different approaches to accessibility. In addition, different possible relationships could exist between problems encountered by disabled and non-disabled users, yet little empirical data have been gathered on this question. Guidelines for accessibility and usability of websites provide ratings of the importance of problems for users, yet little empirical data have been gathered to validate these ratings. A study investigated the accessibility of two websites with 6 disabled (blind) and 6 non-disabled (sighted) people. Problems encountered by the two groups comprised two intersecting sets, with approximately 15% overlap. For one of the two websites, blind people rated problems significantly more severely than sighted people. There was high agreement between participants as to the severity of problems, and agreement between participants and researchers. However, there was no significant agreement between either participants or researchers and the importance/priority ratings provided by accessibility and usability guidelines. Practical and theoretical implications of these results are discussed.

collapse
SESSION: Gaze & eye tracking
Chris North
What are you looking for?: an eye-tracking study of information usage in web search
Edward Cutrell, Zhiwei Guan
Pages: 407-416
doi>10.1145/1240624.1240690
Full text: PDFPDF

Web search services are among the most heavily used applications on the World Wide Web. Perhaps because search is used in such a huge variety of tasks and contexts, the user interface must strike a careful balance to meet all user needs. We describe a study that used eye tracking methodologies to explore the effects of changes in the presentation of search results. We found that adding information to the contextual snippet significantly improved performance for informational tasks but degraded performance for navigational tasks. We discuss possible reasons for this difference and the design implications for better presentation of search results.

collapse
An eye tracking study of the effect of target rank on web search
Zhiwei Guan, Edward Cutrell
Pages: 417-420
doi>10.1145/1240624.1240691
Full text: PDFPDF

Web search engines present search results in a rank ordered list. This works when what a user wants is near the top, but sometimes the information that the user really wants is located at the bottom of the page. This study examined how users' search behaviors vary when target results were displayed at various positions for informational and navigational tasks. We found that when targets were placed relatively low in the first page of search results, people spent more time searching and were less successful in finding the target, especially for informational tasks. Further analysis of eye movements showed that the decrease in search performance was partially due to the fact that users rarely looked at lower ranking results. The large decrease in performance for informational search is probably because users have high confidence in the search engine's ranking; in contrast to navigational tasks, where the target is more obvious from information presented in the results, in informational tasks, users try out the top ranked results even if these results are perceived as less relevant for the task.

collapse
EyePoint: practical pointing and selection using gaze and keyboard
Manu Kumar, Andreas Paepcke, Terry Winograd
Pages: 421-430
doi>10.1145/1240624.1240692
Full text: PDFPDF

We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences.

collapse
A minimal model for predicting visual search in human-computer interaction
Tim Halverson, Anthony J. Hornof
Pages: 431-434
doi>10.1145/1240624.1240693
Full text: PDFPDF

Visual search is an important part of human-computer interaction. It is critical that we build theory about how people visually search displays in order to better support the users' visual capabilities and limitations in everyday tasks. One way of building such theory is through computational cognitive modeling. The ultimate promise for cognitive modeling in HCI it to provide the science base needed for predictive interface analysis tools. This paper discusses computational cognitive modeling of the perceptual, strategic, and oculomotor processes people used in a visual search task. This work refines and rounds out previously reported cognitive modeling and eye tracking analysis. A revised "minimal model" of visual search is presented that explains a variety of eye movement data better than the original model. The revised model uses a parsimonious strategy that is not tied to a particular visual structure or feature beyond the location of objects. Three characteristics of the minimal strategy are discussed in detail.

collapse
SESSION: Online representation of self
A. J. Brush
A familiar face(book): profile elements as signals in an online social network
Cliff A.C. Lampe, Nicole Ellison, Charles Steinfield
Pages: 435-444
doi>10.1145/1240624.1240695
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Using data from a popular online social network site, this paper explores the relationship between profile structure (namely, which fields are completed) and number of friends, giving designers insight into the importance of the profile and how it works to encourage connections and articulated relationships between users. We describe a theoretical framework that draws on aspects of signaling theory, common ground theory, and transaction costs theory to generate an understanding of why certain profile fields may be more predictive of friendship articulation on the site. Using a dataset consisting of 30,773 Facebook profiles, we determine which profile elements are most likely to predict friendship links and discuss the theoretical and design implications of our findings.

collapse
Constructing my online self: avatars that increase self-focused attention
Asimina Vasalou, Adam N. Joinson, Jeremy Pitt
Pages: 445-448
doi>10.1145/1240624.1240696
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Three studies investigated whether users' strategies for customising online avatars increase their self-focused attention, also known as private self-awareness. Study 1 showed that a high number of users adapt their avatars toreflect their own appearance. Study 2 demonstrated that users who perceive their avatars to be similar to their own appearance experience as a result heightened private self-awareness. In Study 3, private self-awareness pervadedsocial interaction taking place over time when users with representative avatars, compared to a control group, reported increased private self-awareness. Drawing from research in interpersonal communication, we suggest that avatars which increase their owners' self-focus may have an influence on online behavior in the context of social computing.

collapse
The truth about lying in online dating profiles
Jeffrey T. Hancock, Catalina Toma, Nicole Ellison
Pages: 449-452
doi>10.1145/1240624.1240697
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Online dating is a popular new tool for initiating romantic relationships, although recent research and media reports suggest that it may also be fertile ground for deception. Unlike previous studies that rely solely on self-report data, the present study establishes ground truth for 80 online daters' height, weight and age, and compares ground truth data to the information provided in online dating profiles. The results suggest that deception is indeed frequently observed, but that the magnitude of the deceptions is usually small. As expected, deceptions differ by gender. Results are discussed in light of the Hyperpersonal model and the self-presentational tensions experienced by online dating participants.

collapse
He says, she says: conflict and coordination in Wikipedia
Aniket Kittur, Bongwon Suh, Bryan A. Pendleton, Ed H. Chi
Pages: 453-462
doi>10.1145/1240624.1240698
Full text: PDFPDF

Wikipedia, a wiki-based encyclopedia, has become one of the most successful experiments in collaborative knowledge building on the Internet. As Wikipedia continues to grow, the potential for conflict and the need for coordination increase as well. This article examines the growth of such non-direct work and describes the development of tools to characterize conflict and coordination costs in Wikipedia. The results may inform the design of new collaborative knowledge systems.

collapse
SESSION: Innovative interactions
Ian Smith
Modeling pointing at targets of arbitrary shapes
Tovi Grossman, Nicholas Kong, Ravin Balakrishnan
Pages: 463-472
doi>10.1145/1240624.1240700
Full text: PDFPDF

We investigate pointing at graphical targets of arbitrary shapes. We first describe a previously proposed probabilistic Fitts' law model [7] which, unlike previous models that only account for rectangular targets, has the potential to handle arbitrary shapes. Three methods of defining the centers of arbitrarily shaped targets for use within the model are developed. We compare these methods of defining target centers, and validate the model using a pointing experiment in which the targets take on various shapes. Results show that the model can accurately account for the varying target shapes. We discuss the implications of our results to interface design.

collapse
Perception of elementary graphical elements in tabletop and multi-surface environments
Daniel Wigdor, Chia Shen, Clifton Forlines, Ravin Balakrishnan
Pages: 473-482
doi>10.1145/1240624.1240701
Full text: PDFPDF

Information shown on a tabletop display can appear distorted when viewed by a seated user. Even worse, the impact of this distortion is different depending on the location of the information on the display. In this paper, we examine how this distortion affects the perception of the basic graphical elements of information visualization shown on displays at various angles. We first examine perception of these elements on a single display, and then compare this to perception across displays, in order to evaluate the effectiveness of various elements for use in a tabletop and multi-display environment. We found that the perception of some graphical elements is more robust to distortion than others. We then develop recommendations for building data visualizations for these environments.

collapse
Exploring and reducing the effects of orientation on text readability in volumetric displays
Tovi Grossman, Daniel Wigdor, Ravin Balakrishnan
Pages: 483-492
doi>10.1145/1240624.1240702
Full text: PDFPDF

Volumetric displays, which provide a 360° view of imagery illuminated in true 3D space, are a promising platform for interactive 3D applications. However, presenting text in volumetric displays can be a challenge, as the text may not be oriented towards the user. This is especially problematic with multiple viewers, as the text could, for example, appear forwards to one user, and backwards to another. In a first experiment we determined the effects of 3D rotations on text readability. Based on the results, we developed and evaluated a new technique which optimizes text orientation for multiple viewers. This technique provided 33% faster group reading times in a collaborative experimental task.

collapse
SESSION: Design theory
Jon Kolko
Research through design as a method for interaction design research in HCI
John Zimmerman, Jodi Forlizzi, Shelley Evenson
Pages: 493-502
doi>10.1145/1240624.1240704
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.

collapse
Sustainable interaction design: invention & disposal, renewal & reuse
Eli Blevis
Pages: 503-512
doi>10.1145/1240624.1240705
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

This paper presents the perspective that sustainability can and should be a central focus of interaction design-a perspective that is termed Sustainable Interaction Design (SID). As a starting point for a perspective of sustainability, design is defined as an act of choosing among or informing choices of future ways of being. This perspective of sustainability is presented in terms of design values, methods, and reasoning. The paper proposes (i) a rubric for understanding the material effects of particular interaction design cases in terms of forms of use, reuse, and disposal, and (ii) several principles to guide SID. The paper illustrates--with particular examples of design critique for interactive products and appeals to secondary research--how two of these principles may be applied to move the effects of designs from less preferred forms of use to more preferred ones. Finally, a vision for incorporating sustainability into the research and practice of interaction design is described.

collapse
Computational composites
Anna Vallgårda, Johan Redström
Pages: 513-522
doi>10.1145/1240624.1240706
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer's point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture.

collapse
SESSION: Play & exercise
Elizabeth Goodman
Jogging the distance
Shannon O'Brien, Florian "Floyd" Mueller
Pages: 523-526
doi>10.1145/1240624.1240708
Full text: PDFPDF

People enjoy jogging with others for social and motivational reasons. However, as reported by forum participants, finding a compatible, local jogging partner who shares the ability to jog at the same pace for the same duration is not always easy. One possible way to overcome this challenge is to expand the range of potential jogging partners by allowing for interaction with remote joggers. We investigated whether a jogging experience supporting conversation between remote partners could be desirable and motivating. We conducted an experiment with 18 volunteers using conventional mobile phones with headsets to support conversations as participants jogged in disjoint, outdoor areas. Results show that a simple audio connection supports participants' need to socialize and allows partners to encourage each other.

collapse
SESSION: Home spirituality
Michael Muller
Sabbath day home automation: "it's like mixing technology and religion"
Allison Woodruff, Sally Augustin, Brooke Foucault
Pages: 527-536
doi>10.1145/1240624.1240710
Full text: PDFPDF

We present a qualitative study of 20 American Orthodox Jewish families' use of home automation for religious purposes. These lead users offer insight into real-life, long-term experience with home automation technologies. We discuss how automation was seen by participants to contribute to spiritual experience and how participants oriented to the use of automation as a religious custom. We also discuss the relationship of home automation to family life. We draw design implications for the broader population, including surrender of control as a design resource, home technologies that support long-term goals and lifestyle choices, and respite from technology.

collapse
Enhancing ubiquitous computing with user interpretation: field testing the home health horoscope
William Gaver, Phoebe Sengers, Tobie Kerridge, Joseph Kaye, John Bowers
Pages: 537-546
doi>10.1145/1240624.1240711
Full text: PDFPDF

Domestic ubiquitous computing systems often rely on inferences about activities in the home, but the open-ended, dynamic and heterogeneous nature of the home poses serious problems for such systems. In this paper, we propose that by shifting the responsibility for interpretation from the system to the user, we can build systems that interact with people at humanly meaningful levels, preserve privacy, and encourage engagement with suggested topics. We describe a system that embodies this hypothesis, using sensors and inferencing software to assess 'domestic wellbeing' and presenting the results to inhabitants through an output chosen for its ambiguity. In a three-month field study of the system, customised for a particular volunteer household, users engaged extensively with the system, discussing and challenging its outputs and responding to the particular topics it raised.

collapse
Home networking and HCI: what hath god wrought?
Erika Shehan, W. Keith Edwards
Pages: 547-556
doi>10.1145/1240624.1240712
Full text: PDFPDF

For much of the industrialized world, network connectivity in the home is commonplace. Despite the large number of networked homes, even the most technically savvy people can have difficulties with home network installation and maintenance. We contend that these problems will not disappear over time as the networking industry matures, but rather are due to structural usability flaws inherent in the design of existing network infrastructure, devices, and protocols. The HCI community can offer a unique perspective to overcoming the challenges associated with home networking. This paper discusses why home networking is difficult, based on analysis of historical, social, and technical factors. It explores how the designs of existing home networking technologies have implications for usability, and examines a range of models for addressing these usability challenges. The paper concludes with a discussion of how these models may impact future research efforts in both HCI and networking.

collapse
SESSION: Programming by professionals
Margaret Burnett
Let's go to the whiteboard: how and why software developers use drawings
Mauro Cherubini, Gina Venolia, Rob DeLine, Andrew J. Ko
Pages: 557-566
doi>10.1145/1240624.1240714
Full text: PDFPDF

Software developers are rooted in the written form of their code, yet they often draw diagrams representing their code. Unfortunately, we still know little about how and why they create these diagrams, and so there is little research to inform the design of visual tools to support developers' work. This paper presents findings from semi-structured interviews that have been validated with a structured survey. Results show that most of the diagrams had a transient nature because of the high cost of changing whiteboard sketches to electronic renderings. Diagrams that documented design decisions were often externalized in these temporary drawings and then subsequently lost. Current visualization tools and the software development practices that we observed do not solve these issues, but these results suggest several directions for future research.

collapse
Aligning development tools with the way programmers think about code changes
Marat Boshernitsan, Susan L. Graham, Marti A. Hearst
Pages: 567-576
doi>10.1145/1240624.1240715
Full text: PDFPDF

Software developers must modify their programs to keepup with changing requirements and designs. Often, aconceptually simple change can require numerous editsthat are similar but not identical, leading to errors andomissions. Researchers have designed programming environmentsto address this problem, but most of thesesystems are counter-intuitive and difficult to use.By applying a task-centered design process, we developeda visual tool that allows programmers to makecomplex code transformations in an intuitive manner.This approach uses a representation that aligns wellwith programmers' mental models of programming structures.The visual language combines textual and graphicalelements and is expressive enough to support a broadrange of code-changing tasks. To simplify learning thesystem, its user interface scaffolds construction and executionof transformations. An evaluation with Java programmerssuggests that the interface is intuitive, easyto learn, and effective on a representative editing task.

collapse
Task and social visualization in software development: evaluation of a prototype
Jason B. Ellis, Shahtab Wahid, Catalina Danis, Wendy A. Kellogg
Pages: 577-586
doi>10.1145/1240624.1240716
Full text: PDFPDF

As open source development has evolved, differentiation of roles and increased sophistication of collaborative processes has occurred. Recently, we described coordination issues in software development and an interactive visualization tool called the Social Health Overview (SHO) developed to address them [12]. This paper presents an empirical evaluation of SHO intended to identify its strengths and weaknesses. Eleven informants in various open source roles were interviewed about their work practices. Eight of these participated in an evaluation comparing three change management tasks in SHO and Bugzilla. Results are discussed with respect to task strategy with each tool and participants' roles.

collapse
SESSION: Web usability
Ed Chi
IGroup: presenting web image search results in semantic clusters
Shuo Wang, Feng Jing, Jibo He, Qixing Du, Lei Zhang
Pages: 587-596
doi>10.1145/1240624.1240718
Full text: PDFPDF

Current web image search engines still rely on user typing textual description: query word(s) for visual targets. As the queries are often short, general or even ambiguous, the images in resulting pages vary in content and style. Thus, browsing with these results is likely to be tedious, frustrating and unpredictable.

IGroup, a proposed image search engine addresses these problems by presenting the result in semantic clusters. The original result set was clustered in semantic groups with a cluster name relevant to user typed queries. Instead of looking through the result pages or modifying queries, IGroup users can refine findings to the interested sub-result sets with a navigational panel, where each cluster (sub-result set) was listed with a cluster name and representative thumbnails of the cluster.

We compared IGroup with a general web image search engine: MSN, in term of efficiency, coverage, and satisfaction with a substantial user study. Our tool shows significant improvement in such criteria.

collapse
Web page revisitation revisited: implications of a long-term click-stream study of browser usage
Hartmut Obendorf, Harald Weinreich, Eelco Herder, Matthias Mayer
Pages: 597-606
doi>10.1145/1240624.1240719
Full text: PDFPDF

This paper presents results of an extensive long-term click-stream study of Web browser usage. Focusing on character and challenges of page revisitation, previous findings from seven to thirteen years ago are updated. The term page re-visit had to be differentiated, since the recurrence rate--the key measure for the share of page revisits--turns out to strongly depend on interpretation. We identify different types of revisitation that allow assessing the quality of current user support and developing concepts for new tools.

Individual navigation strategies differ dramatically and are strongly influenced by personal habits and type of site visited. Based on user action logs and interviews, we distinguished short-term revisits (backtrack or undo) from medium-term (re-utilize or observe) and long-term revisits (rediscover). We analyze current problems and provide suggestions for improving support for different revisitation types.

collapse
Noticing notice: a large-scale experiment on the timing of software license agreements
Nathaniel S. Good, Jens Grossklags, Deirdre K. Mulligan, Joseph A. Konstan
Pages: 607-616
doi>10.1145/1240624.1240720
Full text: PDFPDF

Spyware is an increasing problem. Interestingly, many programs carrying spyware honestly disclose the activities of the software, but users install the software anyway. We report on a study of software installation to assess the effectiveness of different notices for helping people make better decisions on which software to install. Our study of 222 users showed that providing a short summary notice, in addition to the End User License Agreement (EULA), before the installation reduced the number of software installations significantly. We also found that providing the short summary notice after installation led to a significant number of uninstalls. However, even with the short notices, many users installed the program and later expressed regret for doing so. These results, along with a detailed analysis of installation, regret, and survey data about user behaviors informs our recommendations to policymakers and designers for assessing the "adequacy" of consent in the context of software that exhibits behaviors associated with spyware.

collapse
SESSION: Empirical models
Ann Blandford
Meta-analysis of correlations among usability measures
Kasper Hornbæk, Effie Lai-Chong Law
Pages: 617-626
doi>10.1145/1240624.1240722
Full text: PDFPDF

Understanding the relation between usability measures seems crucial to deepen our conception of usability and to select the right measures for usability studies. We present a meta-analysis of correlations among usability measures calculated from the raw data of 73 studies. Correlations are generally low: effectiveness measures (e.g., errors) and efficiency measures (e.g., time) have a correlation of .247 ± .059 (Pearson's product-moment correlation with 95% confidence interval), efficiency and satisfaction (e.g., preference) one of .196 ± .064, and effectiveness and satisfaction one of .164 ± .062. Changes in task complexity do not influence these correlations, but use of more complex measures attenuates them. Standard questionnaires for measuring satisfaction appear more reliable than homegrown ones. Measures of users' perceptions of phenomena are generally not correlated with objective measures of the phenomena. Implications for how to measure usability are drawn and common models of usability are criticized.

collapse
A predictive model of menu performance
Andy Cockburn, Carl Gutwin, Saul Greenberg
Pages: 627-636
doi>10.1145/1240624.1240723
Full text: PDFPDF

Menus are a primary control in current interfaces, but there has been relatively little theoretical work to model their performance. We propose a model of menu performance that goes beyond previous work by incorporating components for Fitts' Law pointing time, visual search time when novice, Hick-Hyman Law decision time when expert, and for the transition from novice to expert behaviour. The model is able to predict performance for many different menu designs, including adaptive split menus, items with different frequencies and sizes, and multi-level menus. We tested the model by comparing predictions for four menu designs (traditional menus, recency and frequency based split menus, and an adaptive 'morphing' design) with empirical measures. The empirical data matched the predictions extremely well, suggesting that the model can be used to explore a wide range of menu possibilities before implementation.

collapse
Endpoint prediction using motion kinematics
Edward Lank, Yi-Chun Nikko Cheng, Jaime Ruiz
Pages: 637-646
doi>10.1145/1240624.1240724
Full text: PDFPDF

Recently proposed novel interaction techniques such as cursor jumping [1] and target expansion for tiled arrangements [13] are predicated on an ability to effectively estimate the endpoint of an input gesture prior to its completion. However, current endpoint estimation techniques lack the precision to make these interaction techniques possible. To address a recognized lack of effective endpoint prediction mechanisms, we propose a new technique for endpoint prediction that applies established laws of motion kinematics in a novel way to the identification of motion endpoint. The technique derives a model of speed over distance that permits extrapolation. We verify our model experimentally using stylus targeting tasks, and demonstrate that our endpoint prediction is almost twice as accurate as the previously tested technique [13] at points more than twice as distant from motion endpoint.

collapse
SESSION: Mobile interaction techniques I
Stephen Brewster
Direct-touch vs. mouse input for tabletop displays
Clifton Forlines, Daniel Wigdor, Chia Shen, Ravin Balakrishnan
Pages: 647-656
doi>10.1145/1240624.1240726
Full text: PDFPDF

We investigate the differences -- in terms of bothquantitative performance and subjective preference -- between direct-touch and mouse input for unimanual andbimanual tasks on tabletop displays. The results of twoexperiments show that for bimanual tasks performed ontabletops, users benefit from direct-touch input. However,our results also indicate that mouse input may be moreappropriate for a single user working on tabletop tasksrequiring only single-point interaction.

collapse
Shift: a technique for operating pen-based interfaces using touch
Daniel Vogel, Patrick Baudisch
Pages: 657-666
doi>10.1145/1240624.1240727
Full text: PDFPDF

Retrieving the stylus of a pen-based device takes time and requires a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are the occlusion of the target by the user's finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users guide the pointer into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary--over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets.

collapse
An alternative to push, press, and tap-tap-tap: gesturing on an isometric joystick for mobile phone text entry
Jacob O. Wobbrock, Duen Horng Chau, Brad A. Myers
Pages: 667-676
doi>10.1145/1240624.1240728
Full text: PDFPDF

A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like "pressure strokes." In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results showed that a joystick on the back could be used at about 70% of the speed of the front, and the front joystick could be used eyes-free at about 80% of the speed of normal use.

collapse
SESSION: Tasks
Scott Klemmer
Disruption and recovery of computing tasks: field study, analysis, and directions
Shamsi T. Iqbal, Eric Horvitz
Pages: 677-686
doi>10.1145/1240624.1240730
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users' interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings.

collapse
CAAD: an automatic task support system
Tye Rattenbury, John Canny
Pages: 687-696
doi>10.1145/1240624.1240731
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Recent HCI research shows strong interest in task management systems (e.g. [19, 27]) that support the multi-tasked nature of information work [13]. These systems either require users to manually create and maintain task representations or they depend on explicit user cues to guide the creation and maintenance process. To access and use the task representations in these systems, users must also specify their current task. This interaction overhead inhibits the adoption of these systems. In this paper, we present a novel approach to task management that automates the creation and maintenance of task representations. Our system supports the user by making commonly used information more "ready-at-hand" through an intuitive visualization of their task representations. Users can correct and organize their task representations by directly manipulating the visualization; however, this interaction is not required. We describe a feasibility study that demonstrates the actual utility (in terms of overhead reduction) and perceived utility of our system.

collapse
Understanding and developing models for detecting and differentiating breakpoints during interactive tasks
Shamsi T. Iqbal, Brian P. Bailey
Pages: 697-706
doi>10.1145/1240624.1240732
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

The ability to detect and differentiate breakpoints during task execution is critical for enabling defer-to-breakpoint policies within interruption management. In this work, we examine the feasibility of building statistical models that can detect and differentiate three granularities (types) of perceptually meaningful breakpoints during task execution, without having to recognize the underlying tasks. We collected ecological samples of task execution data, and asked observers to review the interaction in the collected videos and identify any perceived breakpoints and their type. Statistical methods were applied to learn models that map features of the interaction to each type of breakpoint. Results showed that the models were able to detect and differentiate breakpoints with reasonably high accuracy across tasks. Among many uses, our resulting models can enable interruption management systems to better realize defer-to-breakpoint policies for interactive, free-form tasks.

collapse
SESSION: Emergency action
John Carroll
Implicit coordination in firefighting practice: design implications for teaching fire emergency responders
Zachary O. Toups, Andruid Kerne
Pages: 707-716
doi>10.1145/1240624.1240734
Full text: PDFPDF

Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.

collapse
Back stage on the front lines: perspectives and performance in the combat information center
Paul M. Aoki
Pages: 717-726
doi>10.1145/1240624.1240735
Full text: PDFPDF

While tactical command. control and communication environments might appear to be entirely instrumental in nature, they nevertheless provide a setting for social interaction. This paper describes how such interaction occurs in a particular naval tactical command and control system, focusing on the shared perspectives created by the organizational, administrative and professional aspects of the environment and on issues of self-presentation. It is argued that the complexity and multiplicity of interactional regions in this environment lead to problematic situations for key actors, and that these problems may have relevance to future computing environments.

collapse
Citizen communications in crisis: anticipating a future of ICT-supported public participation
Leysia Palen, Sophia B. Liu
Pages: 727-736
doi>10.1145/1240624.1240736
Full text: PDFPDF

Recent world-wide crisis events have drawn new attention to the role information communication technology (ICT) can play in warning and response activities. Drawing on disaster social science, we consider a critical aspect of post-impact disaster response that does not yet receive much information science research attention. Public participation is an emerging, large-scale arena for computer-mediated interaction that has implications for both informal and formal response. With a focus on persistent citizen communications as one form of interaction in this arena, we describe their spatial and temporal arrangements, and how the emerging information pathways that result serve different post-impact functions. However, command-and-control models do not easily adapt to the expanding data-generating and -seeking activities by the public. ICT in disaster contexts will give further rise to improvised activities and temporary organizations with which formal response organizations need to align.

collapse
SESSION: Design methods
Steve Harrison
Transfer scenarios: grounding innovation with marginal practices
Sara Ljungblad, Lars Erik Holmquist
Pages: 737-746
doi>10.1145/1240624.1240738
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Transfer scenarios is a method developed to support the design of innovative interactive technology. Such a method should help the designer to come up with inventive ideas, and at the same time provide grounding in real human needs. In transfer scenarios, we use marginal practices to encourage a changed mindset throughout the design process. A marginal practice consists of individuals who share an activity that they find meaningful. We regard these individuals not as end-users, but as valuable input in the design process. We applied this method when designing novel applications for autonomous embodied agents, e.g. robots. Owners of unusual pets, such as snakes and spiders, were interviewed - not with the intention to design robot pets, but to determine underlying needs and interests of their practice. The results were then used to design a set of applications for more general users, including a dynamic living-room wall and a set of communicating hobby robots.

collapse
Work-centered design: a case study of a mixed-initiative scheduler
Keith A. Butler, Jiajie Zhang, Chris Esposito, Ali Bahrami, Ron Hebron, David Kieras
Pages: 747-756
doi>10.1145/1240624.1240739
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

We present the case study of a complex, mixed-initiative scheduling system to illustrate Work-Centered Design (WCD), a new approach for the design of information systems. WCD is based on theory of distributed cognition and extends established user-centered methods with abstract task modeling, using innovative techniques for work ontology and top-level algorithms to capture the logic of a human-computer interaction paradigm. WCD addresses a long-standing need for more effective methods of function allocation. The illustrating case study succeeded on a large, difficult problem for aircraft scheduling where prior expensive attempts failed. The new system, called Solver, reduces scheduling labor from 9 person-days a week to about 1 person-hour. These results were obtained from the first user test, demonstrating notable effectiveness of WCD. Further, the value of Solver's higher quality schedules is far-reaching. WCD extends HCI methods to fill an important need for technical problem-solving systems.

collapse
SESSION: Mobile interaction techniques II
Shumin Zhai
Pointing lenses: facilitating stylus input through visual-and motor-space magnification
Gonzalo Ramos, Andy Cockburn, Ravin Balakrishnan, Michel Beaudouin-Lafon
Pages: 757-766
doi>10.1145/1240624.1240741
Full text: PDFPDF

Using a stylus on a tablet computer to acquire small targets can be challenging. In this paper we present pointing lenses -- interaction techniques that help users acquire and select targets by presenting them with an enlarged visual and interaction area. We present and study three pointing lenses for pen-based systems and find that our proposed Pressure-Activated Lens is the top overall performer in terms of speed, accuracy and user preference. In addition, our experimental results not only show that participants find all pointing lenses beneficial for targets smaller than 5 pixels, but they also suggest that this benefit may extend to larger targets as well.

collapse
Comparing physical, automatic and manual map rotation for pedestrian navigation
Will Seager, Danae Stanton Fraser
Pages: 767-776
doi>10.1145/1240624.1240742
Full text: PDFPDF

It is well-established finding that people find maps easier to use when they are aligned so that "up" on the map corresponds to the user's forward direction. With map-based applications on handheld mobile devices, this forward/up correspondence can be maintained in several ways: the device can be physically rotated within the user's hands or the user can manually operate buttons to digitally rotate the map; alternatively, the map can be rotated automatically using data from an electronic compass. This paper examines all three options. In a field experiment, each method is compared against a baseline north-up condition. The study provides strong evidence that physical rotation is the most effective with applications that present the user with a wider map. The paper concludes with some suggestions for design improvements.

collapse
SESSION: Tangibility
Chia Shen
Senspectra: a computationally augmented physical modeling toolkit for sensing and visualization of structural strain
Vincent LeClerc, Amanda Parkes, Hiroshi Ishii
Pages: 801-804
doi>10.1145/1240624.1240744
Full text: PDFPDF

We present Senspectra, a computationally augmented physical modeling toolkit designed for sensing and visualization of structural strain. Senspectra seeks to explore a new direction in computational materiality, incorporating the material quality of malleable elements of an interface into its digital control structure. The system functions as a decentralized sensor network consisting of nodes, embedded with computational capabilities and a full spectrum LED, and flexible joints. Each joint functions as an omnidirectional bend sensing mechanism to sense and communicate mechanical strain between neighboring nodes.

Using Senspectra, a user incrementally assembles and refines a physical 3D model of discrete elements with a real-time visualization of structural strain. While the Senspectra infrastructure provides a flexible modular sensor network platform, its primary application derives from the need to couple physical modeling techniques utilized in architecture and design disciplines with systems for structural engineering analysis. This offers direct manipulation augmented with visual feedback for an intuitive approach to physical real-time finite element analysis, particularly for organic forms.

collapse
Tangible user interface for chemistry education: comparative evaluation and re-design
Morten Fjeld, Jonas Fredriksson, Martin Ejdestig, Florin Duca, Kristina Bötschi, Benedikt Voegtli, Patrick Juchli
Pages: 805-808
doi>10.1145/1240624.1240745
Full text: PDFPDF

Augmented Chemistry (AC) is an application that utilizes a tangible user interface (TUI) for organic chemistry education. The empirical evaluation described in this paper compares learning effectiveness and user acceptance of AC versus the more traditional ball-and-stick model (BSM). Learning effectiveness results were almost the same for both learning environments. User preference and rankings, using NASA-TLX and SUMI, showed more differences and it was therefore decided to focus mainly on improving these aspects in a re-design of the AC system. For enhanced interaction, keyboard-free system configuration, and internal/external database (DB) access, a graphical user interface (GUI) has been incorporated into the TUI. Three-dimensional (3D) rendering has also been improved using shadows and related effects, thereby enhancing depth perception. The re-designed AC system was then compared to the old system by means of a small qualitative user study. This user study showed an improvement in subjective opinions a out the system's ease of use and ease of learning.

collapse
Mechanical constraints as computational constraints in tabletop tangible interfaces
James Patten, Hiroshi Ishii
Pages: 809-818
doi>10.1145/1240624.1240746
Full text: PDFPDF

This paper presents a new type of human-computer interface called Pico (Physical Intervention in Computational Optimization) based on mechanical constraints that combines some of the tactile feedback and affordances of mechanical systems with the abstract computational power of modern computers. The interface is based on a tabletop interaction surface that can sense and move small objects on top of it. The positions of these physical objects represent and control parameters inside a software application, such as a system for optimizing the configuration of radio towers in a cellular telephone network. The computer autonomously attempts to optimize the network, moving the objects on the table as it changes their corresponding parameters in software. As these objects move, the user can constrain their motion with his or her hands, or many other kinds of physical objects. The interface provides ample opportunities for improvisation by allowing the user to employ a rich variety of everyday physical objects as mechanical constraints. This approach leverages the user's mechanical intuition for how objects respond to physical forces. As well, it allows the user to balance the numerical optimization performed by the computer with other goals that are difficult to quantify. Subjects in an evaluation were more effective at solving a complex spatial layout problem using this system than with either of two alternative interfaces that did not feature actuation.

collapse
Intimate interfaces in action: assessing the usability and subtlety of emg-based motionless gestures
Enrico Costanza, Samuel A. Inverso, Rebecca Allen, Pattie Maes
Pages: 819-828
doi>10.1145/1240624.1240747
Full text: PDFPDF

Mobile communication devices, such as mobile phones and networked personal digital assistants (PDAs), allow users to be constantly connected and communicate anywhere and at any time, often resulting in personal and private communication taking place in public spaces. This private -- public contrast can be problematic. As a remedy, we promote intimate interfaces: interfaces that allow subtle and minimal mobile interaction, without disruption of the surrounding environment. In particular, motionless gestures sensed through the electromyographic (EMG) signal have been proposed as a solution to allow subtle input in a mobile context. In this paper we present an expansion of the work on EMG-based motionless gestures including (1) a novel study of their usability in a mobile context for controlling a realistic, multimodal interface and (2) a formal assessment of how noticeable they are to informed observers. Experimental results confirm that subtle gestures can be profitably used within a multimodal interface and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety.

collapse
SESSION: Games
Carl Gutwin
Project massive: self-regulation and problematic use of online gaming
A. Fleming Seay, Robert E. Kraut
Pages: 829-838
doi>10.1145/1240624.1240749
Full text: PDFPDF

A longitudinal design was employed to collect three waves of survey data over a 14 month period from 2790 online gamers. Respondents were asked questions about their gaming activity, motivations, personality, social and emotional environment, and the effect gaming has had on their lives. Prospective analysis was used to establish causal and temporal linkages among the repeatedly measured factors. While the data provide some indication that a player's reasons for playing do influence the development of problematic usage, these effects are overshadowed by the central importance of self-regulation in managing both the timing and amount of play. An individual's level of self-regulatory activity is shown to be very important in allowing them to avoid negative outcomes like problematic use. The role of depression is also discussed. With responsible use, online gaming appears to be a healthy recreational activity that provides millions of people with hours of social entertainment and adaptive diversion. However, failure to manage play behavior can lead to feelings of dependency.

collapse
The life and death of online gaming communities: a look at guilds in world of warcraft
Nicolas Ducheneaut, Nicholas Yee, Eric Nickell, Robert J. Moore
Pages: 839-848
doi>10.1145/1240624.1240750
Full text: PDFPDF

Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or "guilds" to coordinate their actions and accomplish the games' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities.

collapse
Testing the technology: playing games with video conferencing
Archer L. Batcheller, Brian Hilligoss, Kevin Nam, Emilee Rader, Marta Rey-Babarro, Xiaomu Zhou
Pages: 849-852
doi>10.1145/1240624.1240751
Full text: PDFPDF

Video connections can establish a media space in which games may be played, just as people play games while collocated. Experiments with participants playing the game 'Mafia' indicate that people in a video condition have similar levels of satisfaction, fun, and frustration, to those that play while collocated. This finding holds for both those with prior experience using video systems and those without, suggesting it is not merely a "novelty effect." Results differ about whether there exist differences in focus of attention, suspicion/trust, and pointing for people playing the game while using a video system. Implications for both fun and work uses of video are suggested.

collapse
Using heart rate to control an interactive game
Ville Nenonen, Aleksi Lindblad, Ville Häkkinen, Toni Laitinen, Mikko Jouhtio, Perttu Hämäläinen
Pages: 853-856
doi>10.1145/1240624.1240752
Full text: PDFPDF

This paper presents a novel way of using real-time heart rate information to control a physically interactive biathlon (skiing and shooting) computer game. Instead of interfacing the game to an exercise bike or other equipment with speed output, the skiing speed is directly proportional to heart rate. You can freely choose the form of physical exercise, which makes it easier for people with different skill levels and backgrounds to play together. The system can be used with any exercise machine or form. To make playing meaningful instead of simply exercising as hard as you can, a high heart rate impedes the shooting part of the game by making the sight less steady. This balancing mechanism lets the player try out different tactics, varying from very slow skiing and sharp shooting to fast skiing and random shooting. The game has been evaluated in a user study with eight participants. The results show that heart rate interaction is fun and usable interaction method.

collapse
SESSION: Video
Wendy Mackay
Consuming video on mobile devices
Kenton O'Hara, April Slayden Mitchell, Alex Vorbau
Pages: 857-866
doi>10.1145/1240624.1240754
Full text: PDFPDF

Mobile video is now an everyday possibility with a wide array of commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of mobile video, this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available mobile video technologies in their everyday lives. Drawing on reported episodes of mobile video behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise mobile video consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of mobile video technologies and services are discussed.

collapse
Effects of audio and visual surrogates for making sense of digital video
Yaxiao Song, Gary Marchionini
Pages: 867-876
doi>10.1145/1240624.1240755
Full text: PDFPDF

Video surrogates are meant to help people quickly make sense of the content of a video before downloading or seeking more detailed information. In this paper we present the results of a study comparing the effectiveness of three different surrogates for objects in digital video libraries. Thirty-six people participated in a within subjects user study in which they did five tasks for each of three surrogate alternatives: visual alone (a storyboard), audio alone (spoken description), and combined visual and audio (a storyboard augmented with spoken description). The results show that combined surrogates are more effective, strongly preferred, and do not penalize efficiency. The results also demonstrate that spoken descriptions alone lead to better understanding of the video segments than do visual storyboards alone, although people like to have visual surrogates and use them to confirm interpretations and add context. Participants were able to easily use the combined surrogates even though they were not synchronized, suggesting that synchronization of different media channels may not be necessary in surrogates as it is in full video. The results suggest that multimodal surrogates should be incorporated into video retrieval user interfaces and audio surrogates should be used in small display interfaces. The study also raises questions about the need to synchronize different information channels in multimedia surrogates.

collapse
Watching together: integrating text chat with video
Justin D. Weisz, Sara Kiesler, Hui Zhang, Yuqing Ren, Robert E. Kraut, Joseph A. Konstan
Pages: 877-886
doi>10.1145/1240624.1240756
Full text: PDFPDF

Watching video online is becoming increasingly popular, and new video streaming technologies have the potential to transform video watching from a passive, isolating experience into an active, socially engaging experience. However, the viability of an active social experience is unclear: both chatting and watching video require attention, and may interfere with one another and detract from the experience. In this paper, we empirically examine the activity of chatting while watching video online. We examine how groups of friends and strangers interact, and find that chat has a positive influence on social relationships, and people chat despite being distracted. We discuss the benefits and opportunities provided by mixing chat and video, uncover some of the attentional and social challenges inherent in this combination of media, and provide guidance for structuring the viewing experience.

collapse
SESSION: Security
Carlos Jensen
Pictures at the ATM: exploring the usability of multiple graphical passwords
Wendy Moncur, Grégory Leplâtre
Pages: 887-894
doi>10.1145/1240624.1240758
Full text: PDFPDF

Users gain access to cash, confidential information and services at Automated Teller Machines (ATMs) via an authentication process involving a Personal Identification Number (PIN). These users frequently have many different PINs, and fail to remember them without recourse to insecure behaviours. This is not a failing of users. It is a usability failing in the ATM authentication mechanism. This paper describes research executed to evaluate whether users find multiple graphical passwords more memorable than multiple PINs. The research also investigates the success of two memory augmentation strategies in increasing memorability of graphical passwords. The results demonstrate that multiple graphical passwords are substantially more effective than multiple PIN numbers. Memorability is further improved by the use of mnemonics to aid their recall.This study will be of interest to HCI practitioners and information security researchers exploring approaches to usable security.

collapse
Password sharing: implications for security design based on social practice
Supriya Singh, Anuja Cabraal, Catherine Demosthenous, Gunela Astbrink, Michele Furlong
Pages: 895-904
doi>10.1145/1240624.1240759
Full text: PDFPDF

Current systems for banking authentication require that customers not reveal their access codes, even to members of the family. A study of banking and security in Australia shows that the practice of sharing passwords does not conform to this requirement. For married and de facto couples, password sharing is seen as a practical way of managing money and a demonstration of trust. Sharing Personal Identification Numbers (PINs) is a common practice among remote indigenous communities in Australia. In areas with poor banking access, this is the only way to access cash. People with certain disabilities have to share passwords with carers, and PIN numbers with retail clerks. In this paper we present the findings of a qualitative user study of banking and money management. We suggest design criteria for banking security systems, based on observed social and cultural practices of password and PIN number sharing.

collapse
Protecting people from phishing: the design and evaluation of an embedded training email system
Ponnurangam Kumaraguru, Yong Rhee, Alessandro Acquisti, Lorrie Faith Cranor, Jason Hong, Elizabeth Nunge
Pages: 905-914
doi>10.1145/1240624.1240760
Full text: PDFPDF

Phishing attacks, in which criminals lure Internet users to websites that impersonate legitimate sites, are occurring with increasing frequency and are causing considerable harm to victims. In this paper we describe the design and evaluation of an embedded training email system that teaches people about phishing during their normal use of email. We conducted lab experiments contrasting the effectiveness of standard security notices about phishing with two embedded training designs we developed. We found that embedded training works better than the current practice of sending security notices. We also derived sound design principles for embedded training systems.

collapse
SESSION: Emotion & empathy
Diane Schiano
Studying antecedents of emotional experiences in interactive contexts
Sascha Mahlke, Manfred Thüring
Pages: 915-918
doi>10.1145/1240624.1240762
Full text: PDFPDF

This paper describes a research approach to the experimental study of emotional experiences and their connections to other components of user experience in human-technology interaction. We present a model of user experience that integrates interaction characteristics, instrumental and non-instrumental quality perceptions, emotional user reactions and overall judgments of system quality. An experiment is reported to illustrate the application of our approach. System properties of an interactive prototype were varied to produce versions of different usability and aesthetics which in turn led to different perceptions of instrumental and non-instrumental qualities. The results indicate that both quality aspects significantly influence emotional reactions with respect to subjective feelings, facial expressions and physiological responses. These findings are consistent with the users' overall judgments of the systems and show that the perception of both, instrumental and non-instrumental qualities influences the appraisal of interactive systems.

collapse
Patterns of empathy in online communication
Ulrike Pfeil, Panayiotis Zaphiris
Pages: 919-928
doi>10.1145/1240624.1240763
Full text: PDFPDF

This article presents an investigation of empathy within an online community for older people (SeniorNet). Qualitative content analysis of 400 messages from a discussion board about depression was used to determine how empathy is expressed and facilitated in online communication. Special emphasis was placed on determining the components of online empathy. A code scheme that we developed to analyse online empathy is also presented. The findings were compared to offline studies about empathy in order to investigate the influence that the mediating technology has on the phenomenon.

collapse
Expressing emotion in text-based communication
Jeffrey T. Hancock, Christopher Landrigan, Courtney Silver
Pages: 929-932
doi>10.1145/1240624.1240764
Full text: PDFPDF

Our ability to express and accurately assess emotional states is central to human life. The present study examines how people express and detect emotions during text-based communication, an environment that eliminates the nonverbal cues typically associated with emotion. The results from 40 dyadic interactions suggest that users relied on four strategies to express happiness versus sadness, including disagreement, negative affect terms, punctuation, and verbosity. Contrary to conventional wisdom, communication partners readily distinguished between positive and negative valence emotional communicators in this text-based context. The results are discussed with respect to the Social Information Processing model of strategic relational adaptation in mediated communication.

collapse
Exploring affective design for physical controls
Colin Swindells, Karon E. MacLean, Kellogg S. Booth, Michael J. Meitner
Pages: 933-942
doi>10.1145/1240624.1240765
Full text: PDFPDF

Physical controls such as knobs, sliders, and buttons are experiencing a revival as many computing systems progress from personal computing architectures towards ubiquitous computing architectures. We demonstrate a process for measuring and comparing visceral emotional responses of a physical control to performance results of a target acquisition task. In our user study, participants experienced mechanical and rendered friction, inertia, and detent dynamics as they turned a haptic knob towards graphical targets of two different widths and amplitudes. Together, this process and user study provide novel affect- and performance-based design guidance to developers of physical controls for emerging ubiquitous computing environments. Our work bridges extensive human factors work in mechanical systems that peaked in the 1960's, to contemporary trends, with a goal of integrating mechatronic controls into emerging ubiquitous computing systems.

collapse
SESSION: Collaboration at work
Wendy Kellogg
Koala: capture, share, automate, personalize business processes on the web
Greg Little, Tessa A. Lau, Allen Cypher, James Lin, Eben M. Haber, Eser Kandogan
Pages: 943-946
doi>10.1145/1240624.1240767
Full text: PDFPDF

We present Koala, a system that enables users to capture, share, automate, and personalize business processes on the web. Koala is a collaborative programming-by-demonstration system that records, edits, and plays back user interactions as pseudo-natural language scripts that are both human- and machine-interpretable. Unlike previous programming by demonstration systems, Koala leverages sloppy programming that interprets pseudo-natural language instructions (as opposed to formal syntactic statements) in the context of a given web page's elements and actions. Koala scripts are automatically stored in the Koalescence wiki, where a community of users can share, run, and collaboratively develop their "how-to" knowledge. Koala also takes advantage of corporate and personal data stores to automatically generalize and instantiate user-specific data, so that scripts created by one user are automatically personalized for others. Our initial experiences suggest that Koala is surprisingly effective at interpreting instructions originally written for people.

collapse
Understanding memory triggers for task tracking
A.J. Bernheim Brush, Brian R. Meyers, Desney S. Tan, Mary Czerwinski
Pages: 947-950
doi>10.1145/1240624.1240768
Full text: PDFPDF

Software can now track which computer applications and documents you use. This provides us with the potential to help end-users recall past activities for tasks such as status reporting. We describe findings from field observations of eight participants writing their status reports. We observed interesting trends, including the reliance on memory triggers, which were either retrieved from explicit self-reminders, from implicit breadcrumbs left while performing their tasks or directly from memory. Participants perceived spending relatively short amounts of time composing their status reports, suggesting that any technology solution must offer dramatic improvements over current practice.

collapse
Exploring patterns of social commonality among file directories at work
John C. Tang, Clemens Drews, Mark Smith, Fei Wu, Alison Sue, Tessa Lau
Pages: 951-960
doi>10.1145/1240624.1240769
Full text: PDFPDF

We studied files stored by members of a work organization for patterns of social commonality. Discovering identical or similar documents, applications, developer libraries, or other files may suggest shared interests or experience among users. Examining actual file data revealed a number of individual and aggregate practices around file storage. For example, pairs of users typically have many (over 13,000) files in common. A prototype called LiveWire exploits this commonality to make file backup and restore more efficient for a work organization. We removed commonly shared files and focused on specific filetypes that represent user activity to find more meaningful files in common. The Consolidarity project explores how patterns of file commonality could encourage social networking in an organizational context. Mechanisms for addressing the privacy concerns raised by this approach are discussed.

collapse
A study of out-of-turn interaction in menu-based, IVR, voicemail systems
Saverio Perugini, Taylor J. Anderson, William F. Moroney
Pages: 961-970
doi>10.1145/1240624.1240770
Full text: PDFPDF

We present the first user study of out-of-turn interaction inmenu-based, interactive voice-response systems. Out-of-turn interaction is atechnique which empowers the user (unable to respond to the current prompt) totake the conversational initiative by supplying information that is currentlyunsolicited, but expected later in the dialog. The technique permits the userto circumvent any flows of navigation hardwired into the design and navigatethe menus in a manner which reflects their model of the task. We conducted alaboratory experiment to measure the effect of the use of out-of-turninteraction on user performance and preference in a menu-based, voice interfaceto voicemail. Specifically, we compared two interfaces with the exact samehierarchical menu design: one with the capability of accepting out-of-turnutterances and one without this feature. The results indicate that out-of-turninteraction significantly reduces task completion time, improves usability, andis preferred to the baseline. This research studies an unexplored dimension ofthe design space for automated telephone services, namely the nature ofuser-addressable input (utterance) supplied (in-turn vs. out-of-turn), incontrast to more traditional dimensions such as input modality (touch-tone vs.text vs. voice) and style of interaction (menu-based vs. natural language).

collapse
SESSION: Tags, tagging & notetaking
Gina Venolia
Why we tag: motivations for annotation in mobile and online media
Morgan Ames, Mor Naaman
Pages: 971-980
doi>10.1145/1240624.1240772
Full text: PDFPDF

Why do people tag? Users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. We investigate the incentives for annotation in Flickr, a popular web-based photo-sharing system, and ZoneTag, a cameraphone photo capture and annotation tool that uploads images to Flickr. In Flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. ZoneTag, in turn, makes it easier to tag cameraphone photos that are uploaded to Flickr by allowing annotation and suggesting relevant tags immediately after capture.

A qualitative study of ZoneTag/Flickr users exposed various tagging patterns and emerging motivations for photo annotation. We offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. Our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation.

collapse
Selection-based note-taking applications
Aaron Bauer, Kenneth R. Koedinger
Pages: 981-990
doi>10.1145/1240624.1240773
Full text: PDFPDF

The increasing integration of education and technology has led to the development of a range of note-taking applications. Our project's goal is to provide empirical data to guide the design of such note-taking applications by evaluating the behavioral and learning outcomes of different note-taking functionality. The study reported here compares note-taking using a text editor and four interaction techniques. The two standard techniques are typing and copy-paste. The two novel techniques are restricted copy-paste and menu-selection, intended to increase attention and processing respectively. Hypothesized learning gains from the novel techniques were not observed. As implemented these techniques were less efficient and appeared to be more frustrating to use. However, data regarding differences in both note-taking efficiency and learning suggest several important implications for selection-based note-taking applications, such as pasting and highlighting. Our results also indicate that students have strong opinions regarding their note-taking practices, which may complicate potentially beneficial interventions.

collapse
Mobile interaction with visual and RFID tags: a field study on user perceptions
Kaj Mäkelä, Sara Belt, Dan Greenblatt, Jonna Häkkilä
Pages: 991-994
doi>10.1145/1240624.1240774
Full text: PDFPDF

In this paper, we present a study of user perceptions on mobile interaction with visual and RFID tags. Although mobile interaction with tags has been proposed in several earlier studies, user perceptions and usability comparisons of different tag technologies have not been intensively investigated. In contrast to earlier studies, which report on user studies with evaluating new concepts or interaction techniques, we take another approach and examine the current understanding of the techniques and user perceptions on them. Our field study of 50 users charts currently existing user perceptions and reveals potential usability risks that are due to the limited or erroneous understanding of the interaction technique.

collapse
Getting our head in the clouds: toward evaluation studies of tagclouds
A. W. Rivadeneira, Daniel M. Gruen, Michael J. Muller, David R. Millen
Pages: 995-998
doi>10.1145/1240624.1240775
Full text: PDFPDF

Tagclouds are visual presentations of a set of words, typically a set of "tags" selected by some rationale, in which attributes of the text such as size, weight, or color are used to represent features, such as frequency, of the associated terms. This note describes two studies to evaluate the effectiveness of differently constructed tagclouds for the various tasks they can be used to support, including searching, browsing, impression formation and recognition. Based on these studies, we propose a paradigm for evaluating tagclouds and ultimately guidelines for tagcloud construction.

collapse
SESSION: Multimodal interactions
Ed Cuttrell
Supporting multi-point interaction in visual workspaces
Garth Shoemaker, Carl Gutwin
Pages: 999-1008
doi>10.1145/1240624.1240777
Full text: PDFPDF

Multi-point interaction tasks involve the manipulation of several mutually-dependent control points in a visual workspace -- for example, adjusting a selection rectangle in a drawing application. Multi-point interactions place conflicting requirements on the interface: the system must display objects at sufficient scale for detailed manipulation, but it must also provide an efficient means of navigating from one control point to another. Current interfaces lack any explicit support for tasks that combine these two requirements, forcing users to carry out sequences of zoom and pan actions. In this paper, we describe three novel mechanisms for view control that explicitly support multi-point interactions with a single mouse, and preserve both visibility and scale for multiple regions of interest. We carried out a study to compare two of the designs against standard zoom and pan techniques, and found that task completion time was significantly reduced with the new approaches. The study shows the potential of interfaces that combine support for both scale and navigation.

collapse
Multimodal redundancy across handwriting and speech during computer mediated human-human interactions
Edward C. Kaiser, Paulo Barthelmess, Candice Erdmann, Phil Cohen
Pages: 1009-1018
doi>10.1145/1240624.1240778
Full text: PDFPDF

Lecturers, presenters and meeting participants often say what they publicly handwrite. In this paper, we report on three empirical explorations of such multimodal redundancy -- during whiteboard presentations, during a spontaneous brainstorming meeting, and during the informal annotation and discussion of photographs. We show that redundantly presented words, compared to other words used during a presentation or meeting, tend to be topic specific and thus are likely to be out-of-vocabulary. We also show that they have significantly higher tf-idf (term frequency-inverse document frequency) weights than other words, which we argue supports the hypothesis that they are dialogue-critical words. We frame the import of these empirical findings by describing SHACER, our recently introduced Speech and HAndwriting reCognizER, which can combine information from instances of redundant handwriting and speech to dynamically learn new vocabulary.

collapse
SESSION: Distributed interaction
Susan Fussell
An empirical study of the use of visually enhanced voip audio conferencing: the case of IEAC
Xianghua Ding, Thomas Erickson, Wendy A. Kellogg, Stephen Levy, James E. Christensen, Jeremy Sussman, Tracee Vetting Wolf, William E. Bennett
Pages: 1019-1028
doi>10.1145/1240624.1240780
Full text: PDFPDF

IBM Enhanced Audio Conferencing (IEAC) is a VoIP-based audio conferencing system that, like several other systems, provides a visualization showing who is present and their states (e.g., speaking, muted). This paper presents the first study of the use of such a system. Drawing on log files collected over six weeks of use by over 1300 corporate employees, and interviews with 10 of them, we look at how and why various features of the system are used and what sorts of practices are supported. Our findings shed light on the factors that drive the use of visual enhancements to audio conferencing, and suggest further research topics.

collapse
Voyagers and voyeurs: supporting asynchronous collaborative information visualization
Jeffrey Heer, Fernanda B. Viégas, Martin Wattenberg
Pages: 1029-1038
doi>10.1145/1240624.1240781
Full text: PDFPDF

This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us, a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration.

collapse
Turn it this way: grounding collaborative action with remote gestures
David Kirk, Tom Rodden, Danaë Stanton Fraser
Pages: 1039-1048
doi>10.1145/1240624.1240782
Full text: PDFPDF

Remote gesture systems have been shown to provide a significant enhancement to performance in collaborative physical tasks, an effect ascribed to the ability of remote gestures to help ground deictic references. The argument that this effect works by replacing complex referential descriptions with simple pointing behaviours has been drawn into question by recent research. In this paper we significantly unpack the effects of remote gesturing on collaborative language, arguing for a more complex role for remote gestures in interaction. We demonstrate how remote gestures influence the structure of collaborative discourse, and how their use can also influence the temporal nature of the grounding process. Through generating a deeper understanding of these effects of remote gesturing on collaborative language we derive implications for the development and deployment of these technologies.

collapse
SESSION: Learning & education
Deborah Tatar
The validity of a virtual human experience for interpersonal skills education
Kyle Johnsen, Andrew Raij, Amy Stevens, D. Scott Lind, Benjamin Lok
Pages: 1049-1058
doi>10.1145/1240624.1240784
Full text: PDFPDF

Any new tool introduced for education needs to be validated. We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p<.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education.

collapse
Modeling and understanding students' off-task behavior in intelligent tutoring systems
Ryan S.J.d. Baker
Pages: 1059-1068
doi>10.1145/1240624.1240785
Full text: PDFPDF

We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task.

collapse
Improvisation principles and techniques for design
Elizabeth Gerber
Pages: 1069-1072
doi>10.1145/1240624.1240786
Full text: PDFPDF

Existing research addresses how designers create tools to support improvisation, yet little research explores how improvisation offers tools to support design work. This paper explores the potential relationship between improvisation and design, examining how design can benefit from improvisation. The paper argues that improvisation can build perspectives and skills that are critical for designers, such as creative collaboration, fostering innovation, supporting spontaneity, learning through error, and presenting ideas. The paper reviews the use of improvisation activities by designers in a multi-case study. The applications are analyzed to demonstrate individual and group level outcomes in design work.

collapse
Supporting multidisciplinary collaboration: requirements from novel HCI education
Piotr D. Adamczyk, Michael B. Twidale
Pages: 1073-1076
doi>10.1145/1240624.1240787
Full text: PDFPDF

Many collaborative design tools may suffer from being too generic to address the specific complexities inherent in multidisciplinary collaboration. We provide accounts of several multidisciplinary HCI courses at our institution, elaborating on the challenges student teams face when integrating design practice from a wide variety of disciplines. Of particular interest are the distinct approaches that these multidisciplinary teams adopt that differ from more common forms of collaborative design. We suggest reasons for the poor rate of adoption of existing collaborative support tools and outline specific suggestions for directions in both ethnographic studies of multidisciplinary collaboration and collaborative systems design.

collapse
SESSION: Designing for specific cultures
John Thomas
How HCI interprets the probes
Kirsten Boehner, Janet Vertesi, Phoebe Sengers, Paul Dourish
Pages: 1077-1086
doi>10.1145/1240624.1240789
Full text: PDFPDF

We trace how cultural probes have been adopted and adapted by the HCI community. The flexibility of probes has been central to their uptake, resulting in a proliferation of divergent uses and derivatives. The varying patterns of adaptation of the probes reveal important underlying issues in HCI, suggesting underacknowledged disagreements about valid interpretation and the relationship between methods and their underlying methodology. With this analysis, we aim to clarify discussions around probes, and, more importantly, around how we define and evaluate methods in HCI, especially those grounded in unfamiliar conceptions of how research should be done.

collapse
Social dynamics of early stage co-design in developing regions
Divya Ramachandran, Matthew Kam, Jane Chiu, John Canny, James F. Frankel
Pages: 1087-1096
doi>10.1145/1240624.1240790
Full text: PDFPDF

Technology arguably has the potential to play a key role in improving the lives of people in developing regions. However, these communities are not well understood and designers must thoroughly investigate possibilities for technological innovations in these contexts. We describe findings from two field studies in India and one in Uganda where we explore technological solutions in the domains of communication, microfinance and education. Two common underlying themes emerge from these studies: (1) local stakeholders can contribute cultural information relevant to design such as needs and practices through interaction with technology artifacts and (2) unique social network structures embedded within communities are crucial to the acceptance and potential adoption of technology. We end with a synthesis of the three experiences that draws some practical lessons for ICT designers to elicit meaningful feedback and participation from local stakeholders in developing regions communities.

collapse
Localized iterative design for language learning in underdeveloped regions: the PACE framework
Matthew Kam, Divya Ramachandran, Varun Devanathan, Anuj Tewari, John Canny
Pages: 1097-1106
doi>10.1145/1240624.1240791
Full text: PDFPDF

Poor literacy remains a decisive barrier to the economic empowerment of many people in the developing world. Of particular importance is literacy in a widely spoken "world language" such as English, which is typically a second language for these speakers. For complex reasons, schools are often not effective as vehicles for second language learning. In this paper we explore game-like language learning on cell phones. We argue that phones are an excellent technology platform in the typical ecologies of developing countries. We present the PACE framework that is intended to support the rapid, scalable development of language learning software localized for a particular community of learners. These learners are usually skeptical of formal education and of cultural biases they encounter in learning "remote" languages in particular. Localization of content is crucial to make the language relevant to them and to encourage them to adopt it.

collapse
SESSION: Mobile kits & stuff
Yvonne Rogers
iStuff mobile: rapidly prototyping new mobile phone interfaces for ubiquitous computing
Rafael Ballagas, Faraz Memon, Rene Reiners, Jan Borchers
Pages: 1107-1116
doi>10.1145/1240624.1240793
Full text: PDFPDF

iStuff Mobile is the first rapid prototyping framework that helps explore new sensor-based interfaces with existing mobile phones. It focuses on sensor-enhanced physical interfaces for ubiquitous computing scenarios. The framework includes sensor network platforms, mobile phone software, and a proven rapid prototyping framework. Interaction designers can use iStuff Mobile to quickly create and test functional prototypes of novel interfaces without making internal hardware or software modifications to the handset. A visual programming paradigm provides a low threshold for prototyping activities: the system is not difficult to learn. At the same time, the range of examples built using the toolkit demonstrates a high ceiling for prototyping activities: the toolkit places few limits on prototype complexity. A user study shows that the visual programming metaphor enables prototypes to be built faster and encourages more iterations than a previous approach.

collapse
Appropriation of a MMS-based comic creator: from system functionalities to resources for action
Antti Salovaara
Pages: 1117-1126
doi>10.1145/1240624.1240794
Full text: PDFPDF

Technologies can be used - or appropriated - in different ways by different users, but how do the use patterns evolve, and how can design facilitate such evolution? This paper approaches these questions in light of a case study in which a group of 8 high school students used Comeks, a mobile comic strip creator that enables users to exchange rich, expressive multimedia messages. A qualitative analysis of the use processes shows how users turned the functionalities embodied in Comeks into particular resources for communication during the 9-week trial period. The paper discusses the relationship of functionalities of the artifact and the development of resources by presenting how functionalities can be designed to support three ways to appropriate communication technologies: increasing technical mastery, re-channeling existing communication into the new medium and inventing new communicative acts between users.

collapse
Mobile kits and laptop trays: managing multiple devices in mobile information work
Antti Oulasvirta, Lauri Sumari
Pages: 1127-1136
doi>10.1145/1240624.1240795
Full text: PDFPDF

A study at a large IT company shows that mobile information workers frequently migrate work across devices (here: smartphones, desktop PCs, laptops). While having multiple devices provides new opportunities to work in the face of changing resource deprivations, the management of devices is often problematic. The most salient problems are posed by 1) the physical effort demanded by various management tasks, 2) anticipating what data or functionality will be needed, and 3) aligning these efforts with work, mobility, and social situations. Workers' strategies of coping with these problems center on two interwoven activities: the physical handling of devices and cross-device synchronization. These aim at balancing risk and effort in immediate and subsequent use. Workers also exhibit subtle ways to handle devices in situ, appropriating their physical and operational properties. The design implications are discussed.

collapse
SESSION: Novel navigation
Anind Dey
Command strokes with and without preview: using pen gestures on keyboard for command selection
Per Ola Kristensson, Shumin Zhai
Pages: 1137-1146
doi>10.1145/1240624.1240797
Full text: PDFPDF

This paper presents a new command selection method that provides an alternative to pull-down menus in pen-based mobile interfaces. Its primary advantage is the ability forusers to directly select commands from a very large set without the need to traverse menu hierarchies. The proposed method maps the character strings representing the commands onto continuous pen-traces on a stylus keyboard. The user enters a command by stroking part of its character string. We call this method "command strokes." We present the results of three experiments assessing the usefulness of the technique. The first experiment shows that command strokes are 1.6 times faster than the de-facto standard pull-down menus and that users find command strokes more fun to use. The second and third experiments investigate the effect of displaying a visual preview of the currently recognized command while the user is still articulating the command stroke. These experiments show that visual preview does not slow users down and leads to significantly lower error rates and shorter gestures when users enter new unpracticed commands.

collapse
Shallow-depth 3d interaction: design and evaluation of one-, two- and three-touch techniques
Mark Hancock, Sheelagh Carpendale, Andy Cockburn
Pages: 1147-1156
doi>10.1145/1240624.1240798
Full text: PDFPDF

On traditional tables, people frequently use the third dimension to pile, sort and store objects. However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table. To enrich interaction with digital tables, we present the concept of shallow-depth 3D -- 3D interaction with limited depth. Within this shallow-depth 3D environment several common interaction methods need to be reconsidered. Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation (6DOF) on a direct-touch tabletop display. The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity. To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed. Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch.

collapse
Affordances for manipulation of physical versus digital media on interactive surfaces
Lucia Terrenghi, David Kirk, Abigail Sellen, Shahram Izadi
Pages: 1157-1166
doi>10.1145/1240624.1240799
Full text: PDFPDF

This work presents the results of a comparative study in which we investigate the ways manipulation of physical versus digital media are fundamentally different from one another. Participants carried out both a puzzle task and a photo sorting task in two different modes: in a physical 3-dimensional space and on a multi-touch, interactive tabletop in which the digital items resembled their physical counterparts in terms of appearance and behavior. By observing the interaction behaviors of 12 participants, we explore the main differences and discuss what this means for designing interactive surfaces which use aspects of the physical world as a design resource.

collapse
SESSION: People, looking at people
Catalina Danis
Effects of presenting geographic context on tracking activity between cameras
Andreas Girgensohn, Frank Shipman, Thea Turner, Lynn Wilcox
Pages: 1167-1176
doi>10.1145/1240624.1240801
Full text: PDFPDF

A common video surveillance task is to keep track of people moving around the space being monitored. It is often difficult to track activity between cameras because locations such as hallways in office buildings can look quite similar and do not indicate the spatial proximity of the cameras. We describe a spatial video player that orients nearby video feeds with the field of view of the main playing video to aid in tracking between cameras. This is compared with the traditional bank of cameras with and without interactive maps for identifying and selecting cameras. We additionally explore the value of static and rotating maps for tracking activity between cameras. The study results show that both the spatial video player and the map improve user performance when compared to the camera-bank interface. Also, subjects change cameras more often with the spatial player than either the camera bank or the map, when available.

collapse
Dynamic shared visual spaces: experimenting with automatic camera control in a remote repair task
Abhishek Ranjan, Jeremy P. Birnholtz, Ravin Balakrishnan
Pages: 1177-1186
doi>10.1145/1240624.1240802
Full text: PDFPDF

We present an experimental study of automatic camera control in the performance of collaborative remote repair tasks using video-mediated communication. Twelve pairs of participants, one "helper" and one "worker," completed a series of Lego puzzle tasks using both a static camera and an automatic camera system that was guided in part by tracking the worker's hand position. Results show substantial performance benefits for the automatic system, particularly for complex tasks. The implications of these results are discussed, along with some lessons for the use of motion tracking as a driver for camera control.

collapse
"Look!": using the gaze direction of embodied agents
Johann Schrammel, Arjan Geven, Reinhard Sefelin, Manfred Tscheligi
Pages: 1187-1190
doi>10.1145/1240624.1240803
Full text: PDFPDF

This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent's line of sight, whether the agent's gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent's gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent's gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent's gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings.

collapse
Museum guide robot based on sociological interaction analysis
Yoshinori Kuno, Kazuhisa Sadazuka, Michie Kawashima, Keiichi Yamazaki, Akiko Yamazaki, Hideaki Kuzuoka
Pages: 1191-1194
doi>10.1145/1240624.1240804
Full text: PDFPDF

We are currently working on a museum guide robot with an emphasis on "friendly" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.

collapse
SESSION: Input techniques
Gonzalo Ramos
Bubbling menus: a selective mechanism for accessing hierarchical drop-down menus
Theophanis Tsandilas, m. c. schraefel
Pages: 1195-1204
doi>10.1145/1240624.1240806
Full text: PDFPDF

This paper introduces bubbling menus, a new design for cascading drop-down menus. Bubbling menus combine the bubble cursor [10] with directional mouse-gesture techniques to facilitate the access of certain items in a menu, such as frequently selected items. Through an extensive iterative design process, we explore bubbling menus in the context of adaptive and customizable user interfaces. Unlike other adaptation and customization techniques such as split menus, bubbling menus do not disrupt the original structure of menus and enable the activation of menus far from a menu bar. Results from two evaluation studies presented in the paper show that bubbling menus provide an effective alternative to accelerate menu selections tasks.

collapse
Command line or pretty lines?: comparing textual and visual interfaces for intrusion detection
Ramona Su Thompson, Esa M. Rantanen, William Yurcik, Brian P. Bailey
Page: 1205
doi>10.1145/1240624.1240807
Full text: PDFPDF

Intrusion detection (ID) is one of network security engineers' most important tasks. Textual (command-line) and visual interfaces are two common modalities used to support engineers in ID. We conducted a controlled experiment comparing a representative textual and visual interface for ID to develop a deeper understanding about the relative strengths and weaknesses of each. We found that the textual interface allows users to better control the analysis of details of the data through the use of rich, powerful, and flexible commands while the visual interface allows better discovery of new attacks by offering an overview of the current state of the network. With this understanding, we recommend designing a hybrid interface that combines the strengths of textual and visual interfaces for the next generation of tools used for intrusion detection.

collapse
Pointing and beyond: an operationalization and preliminary evaluation of multi-scale searching
Emmanuel Pietriga, Caroline Appert, Michel Beaudouin-Lafon
Pages: 1215-1224
doi>10.1145/1240624.1240808
Full text: PDFPDF

A number of experimental studies based on domain-specific tasks have evaluated the efficiency of navigation techniques for searching multi-scale worlds. The discrepancies among their results call for a more generic framework similar in spirit to Fitts' reciprocal pointing task, but adapted to a task that significantly differs from pure pointing. We introduce such a framework based on an abstract task and evaluate how four multi-scale navigation techniques perform in one particular multi-scale world configuration. Experimental findings indicate that, in this context, pan & zoom combined with an overview is the most efficient technique of all four, and that focus + context techniques perform better than classical pan & zoom. We relate these findings to more realistic situations, discuss their applicability, and how the framework can be used to cover a broad range of situations.

collapse
SESSION: Location aware systems
Dianne Murray
Social practices in location-based collecting
Kenton O'Hara, Tim Kindberg, Maxine Glancy, Luciana Baptista, Byju Sukumaran, Gil Kahana, Julie Rowbotham
Pages: 1225-1234
doi>10.1145/1240624.1240810
Full text: PDFPDF

The use of location-based technology to augment visitor experiences has received considerable attention over the years. In this paper, we take an alternative perspective on these kinds of location-based experiences by focussing on the collecting and keeping of location-based content as opposed to simply the in situ consumption of content. We describe a trial of a location-based experience at London zoo in which mobile camera phones were used to access digital content at particular animal enclosures around the zoo. Through the fieldwork we demonstrate ways in which collecting and keeping have important social values over and above simply consuming the content in situ. More specifically, the role of the collection of location-based content in identity work; in developing a sense of challenge and achievement; in defining a sense of group camaraderie; and in creating a playful sense of competition among group members. Further, we see how narratives told around the collected location-based content over time imbue it with additional value. These narratives become part of the resources through which relationships with family and friends get actively constructed. We discuss how these aspects have different design implications from the in-situ consumption model of location-based experiences and tensions this introduces.

collapse
Capturing, sharing, and using local place information
Pamela J. Ludford, Reid Priedhorsky, Ken Reily, Loren Terveen
Pages: 1235-1244
doi>10.1145/1240624.1240811
Full text: PDFPDF

With new technology, people can share information about everyday places they go; the resulting data helps others find and evaluate places. Recent applications like Dodgeball and Sharescape repurpose everyday place information: users create local place data for personal use, and the systems display it for public use. We explore both the opportunities -- new local knowledge, and concerns -- privacy risks, raised by this implicit information sharing. We conduct two empirical studies: subjects create place data when using PlaceMail, a location-based reminder system, and elect whether to share it on Sharescape, a community map-building system. We contribute by: (1) showing location-based reminders yield new local knowledge about a variety of places, (2) identifying heuristics people use when deciding what place-related information to share (and their prevalence), (3) detailing how these decision heuristics can inform local knowledge sharing system design, and (4) identifying new uses of shared place information, notably opportunistic errand planning.

collapse
Show me the way to Monte Carlo: density-based trajectory navigation
Steven Strachan, John Williamson, Roderick Murray-Smith
Pages: 1245-1248
doi>10.1145/1240624.1240812
Full text: PDFPDF

We demonstrate the use of uncertain prediction in asystem for pedestrian navigation via audio with a combination ofGlobal Positioning System data, a music player, inertial sensing,magnetic bearing data and Monte Carlo sampling for a densityfollowing task, where a listener's music is modulated according tothe changing predictions of user position with respect to a targetdensity, in this case a trajectory or path. We show that this system enables eyes-free navigation around set trajectories or paths unfamiliar to the user and demonstrate that the system may be used effectively for varying trajectory width and context.

collapse
Mapmover: a case study of design-oriented research into collective expression and constructed publics
Carl DiSalvo, Jeff Maki, Nathan Martin
Pages: 1249-1252
doi>10.1145/1240624.1240813
Full text: PDFPDF

In this paper we present the MapMover project as a case study into the use and design of an interactive system for collective expression. Informed by analysis and reflection we advance the concept of constructed publics: publics that are established, shaped, and maintained through the actions and influence of others. We conclude by discussing the relevance of constructed publics as a theorectical frame for the analysis and evaluation of projects in the domains of urban computing and exploratory design in HCI.

collapse
SESSION: Social network sharing
Danyel Fisher
Follow the reader: filtering comments on slashdot
Cliff A.C. Lampe, Erik Johnston, Paul Resnick
Pages: 1253-1262
doi>10.1145/1240624.1240815
Full text: PDFPDF

Large-scale online communities need to manage the tension between critical mass and information overload. Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content. By default, comments with low ratings are hidden. Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings. Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users. We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users. One strategy is to create static schemas that capture the filtering preferences of different groups of readers. Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers. For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments.

collapse
Recent shortcuts: using recent interactions to support shared activities
John C. Tang, James Lin, Jeffrey Pierce, Steve Whittaker, Clemens Drews
Pages: 1263-1272
doi>10.1145/1240624.1240816
Full text: PDFPDF

We present an empirical study of teams that revealed the amount of extraneous individual work needed to enable collaboration: finding references to other people, finding files to attach to email, managing incoming email attachments, managing the variety of files used in shared activities, and tracking what work is owed to others. Much of this work involves finding recently accessed objects that are needed again in the user's current task focus. These observations led to the design of Recent Shortcuts, a tool to help support coordination by making recently used objects easily accessible. Recent Shortcuts enables quick access to people (including groups of people), received attachments, files, and file folders that the user interacted with recently for re-use in the user's current context. Recent Shortcuts makes it easy to use these objects across applications with no additional user input and minimal changes to the user's applications or work practice. Early user experiences with a working prototype led to an extension that integrates recently accessed objects across multiple devices.

collapse
Comedia: mobile group media for active spectatorship
Giulio Jacucci, Antti Oulasvirta, Tommi Ilmonen, John Evans, Antti Salovaara
Pages: 1273-1282
doi>10.1145/1240624.1240817
Full text: PDFPDF

Previous attempts to support spectators at large-scale events have concentrated separately on real-time event information, awareness cues, or media-sharing applications. CoMedia combines a group media space with event information and integrates reusable awareness elements throughout. In two field trials, one at a rally and the other at a music festival, we found that CoMedia facilitated onsite reporting to offsite members, coordination of group action, keeping up to date with others, spectating remotely, and joking. In these activities, media, awareness cues, and event information were often used in concert, albeit assuming differing roles. We show that the integrated approach better supports continuous interweaving of use with the changing interests and occurrences in large-scale events.

collapse
SESSION: Augmentation, automation & agents
Alan Blackwell
Demonstrating the viability of automatically generated user interfaces
Jeffrey Nichols, Duen Horng Chau, Brad A. Myers
Pages: 1283-1292
doi>10.1145/1240624.1240819
Full text: PDFPDF

We conducted a user study that demonstrates that automatically generated interfaces can support better usability through increased flexibility in two dimensions. First, we show that automatic generation can improve usability by moving interfaces that are constrained by cost and poor interaction primitives to another device with better interactive capabilities: subjects were twice as fast and four times as successful at completing tasks with automatically generated interfaces on a PocketPC device as with the actual appliance interfaces. Second, we show that an automatic generator can improve usability by automatically ensuring that new interfaces are generated to be consistent with users' previous experience: subjects were also twice as fast using interfaces consistent with their experiences as compared to normally generated interfaces. These two results demonstrate that automatic interface generation is now viable and especially desirable where users will benefit from individualized interfaces or where human designers are constrained by cost and other factors.

collapse
The role of choice and customization on users' interaction with embodied conversational agents: effects on perception and performance
Jun Xiao, John Stasko, Richard Catrambone
Pages: 1293-1302
doi>10.1145/1240624.1240820
Full text: PDFPDF

We performed an empirical study exploring people's interactions with an embodied conversational agent (ECA) while performing two tasks. Conditions varied with respect to 1) whether participants were allowed to choose an agent and its characteristics and 2) the putative quality or appropriateness of the agent for the tasks. For both tasks, selection combined with the illusion of further customization significantly improved participants' overall subjective impressions of the ECAs while putative quality had little or no effect. Additionally, performance data revealed that the ECA's motivation and persuasion effects were significantly enhanced when participants chose agents to use. We found that user expectations about and perceptions of the interaction between themselves and an ECA depended very much on the individual's preconceived notions and preferences of various ECA characteristics and might deviate greatly from the models that ECA designers intend to portray.

collapse
SESSION: Distributed coordination
John Tang
Seconds matter: improving distributed coordination bytracking and visualizing display trajectories
Mike Fraser, Michael R. McCarthy, Muneeb Shaukat, Phillip Smith
Pages: 1303-1312
doi>10.1145/1240624.1240822
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Pauses in distributed groupware activity can indicate anything from technical latency through infrastructure failure to a participant's thoughtful contemplation. Unraveling these ambiguities highlights mismatches between unseen off-screen activities and on-screen cursor behaviors. In this paper we suggest that groupware systems have typically been poor at representing off-screen activities, and introduce the concept of display trajectories to bridge the sensor gap between the display and its surrounding space. We consider requirements for display trajectories using the distributed social scientific analysis of video data as an example domain. Drawing on these requirements, we prototype a freeform whiteboard pen tracking and visualization technique around displays using ultrasound. We describe an experiment which inspects the impact of display trajectories on remote response efficiency. Our findings show that visualization of the display trajectory improves participants' ability to coordinate their actions by one second per interaction turn, reducing latency in organizing turn taking by a 'standard maximum' conversation pause.

collapse
FASTDash: a visual dashboard for fostering awareness in software teams
Jacob T. Biehl, Mary Czerwinski, Greg Smith, George G. Robertson
Pages: 1313-1322
doi>10.1145/1240624.1240823
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Software developers spend significant time gaining and maintaining awareness of fellow developers' activities. FASTDash is a new interactive visualization that seeks to improve team activity awareness using a spatial representation of the shared code base that highlights team members' current activities. With FASTDash, a developer can quickly determine which team members have source files checked out, which files are being viewed, and what methods and classes are currently being changed. The visualization can be annotated, allowing programmers to supplement activity information with additional status details. It provides immediate awareness of potential conflict situations, such as two programmers editing the same source file. FASTDash was developed through user-centered design, including surveys, team interviews, and in situ observation. Results from a field study show that FASTDash improved team awareness, reduced reliance on shared artifacts, and increased project-related communication. Additionally, the team that participated in our field study continues to use FASTDash.

collapse
A study of emergency response work: patterns of mobile phone interaction
Jonas Landgren, Urban Nulden
Pages: 1323-1332
doi>10.1145/1240624.1240824
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

This paper presents descriptive accounts of time-critical organizing in the domain of emergency response. Patterns of mobile phone interaction in such work is analyzed showing how the dyadic exchange of mobile phone numbers between the actors plays an important role in the social interactions in the organizing and sensemaking of the emergency. Enacted sensemaking is used as an analytical framework. Implications for design of emergency response information technology are outlined and discussed.

collapse
SESSION: Usability
Dennis Wixon
ExperiScope: an analysis tool for interaction data
François Guimbretiére, Morgan Dixon, Ken Hinckley
Pages: 1333-1342
doi>10.1145/1240624.1240826
Full text: PDFPDF

We present ExperiScope, an analytical tool to help designers and experimenters explore the results of quantitative evaluations of interaction techniques. ExperiScope combines a new visualization incorporating aspects of the KLM and the three-state model with an interface helping users to rapidly cluster similar patterns of interactions. The tool makes it easy to identify and compare key patterns of use encountered during data collection. This promotes a deeper understanding of the results of a given evaluation.We illustrate the advantages of this tool by revisiting the data collected for an experiment conducted by Hinckley et al. [19] which compared different mode switching techniques. Our results show that our tool complements the previously reported results by offering insights about error behavior and the impact of mode switching on user performance.By providing a more fine-grained analysis of the data gathered during empirical evaluations, we hope that our tool will improve researchers' understanding of existing and newly developed interaction techniques.

collapse
Context & usability testing: user-modeled information presentation in easy and difficult driving conditions
Jiang Hu, Andi Winterboer, Clifford I. Nass, Johanna D. Moore, Rebecca Illowsky
Pages: 1343-1346
doi>10.1145/1240624.1240827
Full text: PDFPDF

A 2x2 enhanced Wizard-of-Oz experiment (N = 32) was conducted to compare two different approaches to presenting information to drivers in easy and difficult driving conditions. Data of driving safety, evaluation of the spoken dialogue system, and perception of self were analyzed. Results show that the user-modeled summarize-and-refine (UMSR) approach led to more efficient information retrieval than did the summarize-and-refine (SR) approach. However, depending on driving condition, higher efficiency did not always translate into pleasant subjective experience. Implications for usability testing and interface design were presented, followed by discussions of future research directions.

collapse
Tracking the interaction of users with AJAX applications for usability testing
Richard Atterer, Albrecht Schmidt
Pages: 1347-1350
doi>10.1145/1240624.1240828
Full text: PDFPDF

In this paper, we introduce an implementation for detailed monitoring of user actions on web pages. It addresses the problem that the log data recorded by standard web servers is not sufficient for the tracking of users on AJAX websites, e.g. to conduct a usability test. Using standard web technologies, our HTTP proxy can record very detailed usage information, such as mouse movements, clicks, key presses and scrolling, together with the exact HTML DOM tree objects involved. As we show in several case studies, the tracking also works across multiple websites, none of which needs to be under our control. This approach is much less invasive than previous efforts: The test person does not need to install software on her computer, and in certain operation modes, no configuration changes at all are required on her computer. Our research indicates that if the technology described in this paper is employed, arbitrary visitors of a website are more likely to take part in a usability test offered by that site -- this facilitates recruiting test participants over the Internet.

collapse
SESSION: Kids & family
John Zimmerman
Grow and know: understanding record-keeping needs for tracking the development of young children
Julie A. Kientz, Rosa I. Arriaga, Marshini Chetty, Gillian R. Hayes, Jahmeilah Richardson, Shwetak N. Patel, Gregory D. Abowd
Pages: 1351-1360
doi>10.1145/1240624.1240830
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

From birth through age five, children undergo rapid development and learn skills that will influence them their entire lives. Regular visits to the pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. However, new parents are often overwhelmed with new responsibilities, and we believe there is an opportunity for computing technology to assist in this process. In this paper, we present a qualitative study aimed at uncovering some specific needs for record-keeping and analysis for new parents and their network of caregivers. Through interviews and focus groups, we have confirmed assumptions about the rationales parents have and the functions required for using technology for record-keeping. We also identify new themes, potential prototypes, and design guidelines for this domain.

collapse
Sharing motion information with close family and friends
Frank R. Bentley, Crysta J. Metcalf
Pages: 1361-1370
doi>10.1145/1240624.1240831
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

We present the Motion Presence application, an augmented phone book style application that allows close friends and family to view each other's current motion status ("moving" or "not moving") on their mobile phones. We performed a two week long field trial with 10 participants to observe usage and investigate any privacy concerns that might arise. We found that our participants used the motion information to infer location and activity as well as to plan communication, to help in coordinating in-person get-togethers, and to stay connected to patterns in each others' lives. Participants saw the motion data as mostly confirming their existing thoughts about the locations and activities of others and expressed few privacy concerns. In fact, they frequently asked for more information to be shared to make the application more compelling.

collapse
Comicboarding: using comics as proxies for participatory design with children
Neema Moraveji, Jason Li, Jiarong Ding, Patrick O'Kelley, Suze Woolf
Pages: 1371-1374
doi>10.1145/1240624.1240832
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Comicboarding is a participatory design method that uses specially created comic books to generate engaging, productive brainstorming sessions with children. By leveraging known plot formats, interaction styles, and characters in comics, researchers can elicit ideas even from children who are not accustomed to brainstorming, such as those from schools were rote learning is the norm. We conducted an experiment using two variants of the comicboarding methodology with 17 children in China, where traditional participatory design may fail in the face of local cultural practices. The results suggest that comicboarding holds promise for co-design with children.

collapse
SESSION: Alternative interaction
Michel Beaudouin-Lafon
Pressure marks
Gonzalo A. Ramos, Ravin Balakrishnan
Pages: 1375-1384
doi>10.1145/1240624.1240834
Full text: PDFPDF

Selections and actions in GUI's are often separated -- i.e. an action or command typically follows a selection. This sequence imposes a lower bound on the interaction time that is equal to or greater than the sum of its parts. In this paper, we introduce pressure marks -- pen strokes where the variations in pressure make it possible to indicate both a selection and an action simultaneously. We propose a series of design guidelines from which we develop a set of four basictypes of pressure marks. We first assess the viability of this set through an exploratory study that looks at the way users draw straight and lasso pressure marks of different sizes and orientations. We then present the results of a quantitative experiment that shows that users perform faster selection-action interactions with pressure marks than with a combination of lassos and pigtails. Based on these results, we present and discuss a number of interaction designs that incorporate pressure marks.

collapse
Augmenting the mouse with pressure sensitive input
Jared Cechanowicz, Pourang Irani, Sriram Subramanian
Pages: 1385-1394
doi>10.1145/1240624.1240835
Full text: PDFPDF

In this paper we investigate the use of a uni-pressure and dual-pressure augmented mouse. With a pressure augmented mouse users can simultaneously control cursor positions as well as multiple levels of discrete selection modes for common desktop application tasks. Two or more independent pressure sensors can be mounted onto several locations on the body of the mouse. To highlight the design potential of a pressure augmented mouse we conducted a multi-part study. In the first part we identified the number of maximum discrete levels controllable with a uni-pressure augmented mouse, the most appropriate locations for installing pressure sensors on the mouse, and the design of new interaction techniques to support selection with pressure-based input. In a follow-up design we introduced an additional sensor and two different types of selection techniques to control a larger number of discrete levels with two pressure sensors. Our results show that users can comfortably control up to 64 modes with a dual-pressure augmented mouse. We discuss the findings of our results in the context of several desktop interaction techniques and identify several design recommendations.

collapse
Earpod: eyes-free menu selection using touch input and reactive audio feedback
Shengdong Zhao, Pierre Dragicevic, Mark Chignell, Ravin Balakrishnan, Patrick Baudisch
Pages: 1395-1404
doi>10.1145/1240624.1240836
Full text: PDFPDF

We present the design and evaluation of earPod: an eyes-free menu technique using touch input and reactive auditory feedback. Studies comparing earPod with an iPod-like visual menu technique on reasonably-sized static menus indicate that they are comparable in accuracy. In terms of efficiency (speed), earPod is initially slower, but outperforms the visual technique within 30 minutes of practice. Our results indicate that earPod is potentially a reasonable eyes-free menu technique for general use, and is a particularly exciting technique for use in mobile device interfaces.

collapse
SESSION: Usability evaluation
Robin Jeffries
What happened to remote usability testing?: an empirical study of three methods
Morten Sieker Andreasen, Henrik Villemann Nielsen, Simon Ormholt Schrøder, Jan Stage
Pages: 1405-1414
doi>10.1145/1240624.1240838
Full text: PDFPDF

The idea of conducting usability tests remotely emerged ten years ago. Since then, it has been studied empirically, and some software organizations employ remote methods. Yet there are still few comparisons involving more than one remote method. This paper presents results from a systematic empirical comparison of three methods for remote usability testing and a conventional laboratory-based think-aloud method. The three remote methods are a remote synchronous condition, where testing is conducted in real time but the test monitor is separated spatially from the test subjects, and two remote asynchronous conditions, where the test monitor and the test subjects are separated both spatially and temporally. The results show that the remote synchronous method is virtually equivalent to the conventional method. Thereby, it has the potential to conveniently involve broader user groups in usability testing and support new development approaches. The asynchronous methods are considerably more time-consuming for the test subjects and identify fewer usability problems, yet they may still be worthwhile.

collapse
Usability testing: what have we overlooked?
Gitte Lindgaard, Jarinee Chattratichart
Pages: 1415-1424
doi>10.1145/1240624.1240839
Full text: PDFPDF

For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.

collapse
Touchstone: exploratory design of experiments
Wendy E. Mackay, Caroline Appert, Michel Beaudouin-Lafon, Olivier Chapuis, Yangzhou Du, Jean-Daniel Fekete, Yves Guiard
Pages: 1425-1434
doi>10.1145/1240624.1240840
Full text: PDFPDF

Touchstone is an open-source experiment design platform designed to help establish a solid research foundation for HCI in the area of novel interaction techniques. Touchstone includes a design platform for exploring alternative designs of controlled laboratory experiments, a run platform for running subjects and a limited analysis platform for advice and access to on-line statistics packages. Designed for HCI researchers and their students, Touchstone facilitates the process of creating new experiments, as well as replicating and extending experiments in the research literature. We tested Touchstone by designing two controlled experiments. One illustrates how to create a new experiment from scratch. The other replicates and extends a previous study of multiscale pointing interaction techniques: OrthoZoom was fastest, followed by bi-manual Pan & Zoom; SDAZ and traditional Pan & Zoom were consistently slower.

collapse
SESSION: Programming by & with end-users
Les Nelson
Making mashups with marmite: towards end-user programming for the web
Jeffrey Wong, Jason I. Hong
Pages: 1435-1444
doi>10.1145/1240624.1240842
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

There is a tremendous amount of web content available today, but it is not always in a form that supports end-users' needs. In many cases, all of the data and services needed to accomplish a goal already exist, but are not in a form amenable to an end-user. To address this problem, we have developed an end-user programming tool called Marmite, which lets end-users create so-called mashups that re-purpose and combine existing web content and services. In this paper, we present the design, implementation, and evaluation of Marmite. An informal user study found that programmers and some spreadsheet users had little difficulty using the system.

collapse
Vio: a mixed-initiative approach to learning and automating procedural update tasks
John Zimmerman, Anthony Tomasic, Isaac Simmons, Ian Hargraves, Ken Mohnkern, Jason Cornwell, Robert Martin McGuire
Pages: 1445-1454
doi>10.1145/1240624.1240843
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Today many workers spend too much of their time translating their co-workers' requests into structures that information systems can understand. This paper presents the novel interaction design and evaluation of VIO, an agent that helps workers trans late request. VIO monitors requests and makes suggestions to speed up the translation. VIO allows users to quickly correct agent errors. These corrections are used to improve agent performance as it learns to automate work. Our evaluations demonstrate that this type of agent can significantly reduce task completion time, freeing workers from mundane tasks.

collapse
Storytelling alice motivates middle school girls to learn computer programming
Caitlin Kelleher, Randy Pausch, Sara Kiesler
Pages: 1455-1464
doi>10.1145/1240624.1240844
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.

collapse
SESSION: Trust & engagement
Terry Winograd
Multiview: improving trust in group video conferencing through spatial faithfulness
David T. Nguyen, John Canny
Pages: 1465-1474
doi>10.1145/1240624.1240846
Full text: PDFPDF

Video conferencing is still considered a poor alternative to face-to-face meetings. In the business setting, where these systems are most prevalent, the misuse of video conferencing systems can have detrimental results, especially in high-stakes communications. Prior work suggests that spatial distortions of nonverbal cues, particularly gaze and deixis, negatively impact many aspects of effective communication in dyadic communications. However, video conferencing systems are often used for group-to-group meetings where spatial distortions are exacerbated. Meanwhile, its effects on the group dynamic are not well understood. In this study, we examine the effects that spatial distortions of nonverbal cues have on inter-group trust formation. We conducted a large (169 participant) study of group conferencing under various conditions. We found that the use of systems that introduce spatial distortions negatively affect trust formation patterns. On the other hand, these effects are essentially eliminated by using a spatially faithful video conferencing system.

collapse
Presence and engagement in an interactive drama
Steven Dow, Manish Mehta, Ellie Harmon, Blair MacIntyre, Michael Mateas
Pages: 1475-1484
doi>10.1145/1240624.1240847
Full text: PDFPDF

In this paper we present the results of a qualitative, empirical study exploring the impact of immersive technologies on presence and engagement, using the interactive drama Façade as the object of study. In this drama, players are situated in a married couple's apartment, and interact primarily through conversation with the characters and manipulation of objects in the space. We present participants' experiences across three different versions of Façade -- augmented reality (AR) and two desktop computing based implementations, one where players communicate using speech and the other using typed keyboard input. Through interviews and observations of players, we find that immersive AR can create an increased sense of presence, confirming generally held expectations. However, we demonstrate that increased presence does not necessarily lead to more engagement. Rather, mediation may be necessary for some players to fully engage with certain interactive media experiences.

collapse
Engaging constable: revealing art with new technology
Dirk vom Lehn, Jon Hindmarsh, Paul Luff, Christian Heath
Pages: 1485-1494
doi>10.1145/1240624.1240848
Full text: PDFPDF

Museums increasingly deploy new technologies to enhance visitors' experience of their exhibitions. They primarily rely on touch-screen computer systems, PDAs and digital audio-guides. Tate Britain recently employed two innovative systems in one of their major exhibitions of John Constable's work; a gestural interface and a touch-screen panel, both connected to large projection screens. This paper reports on the analysis of video-recordings and field observations of visitors' action and interaction. It explores how people interact with and around the systems, how they configure the space around the installation and how they examine and discover their properties. It suggests that designers of interfaces and installations developed for museum exhibitions face particular challenges, such as the transparency of the relationship between people's actions and the system' response, the provision of opportunities for individual and collaborative experiences and the interweaving of technological and aesthetic experiences.

collapse
SESSION: Models of mobile interaction
Robert St. Amant
Modeling human performance of pen stroke gestures
Xiang Cao, Shumin Zhai
Pages: 1495-1504
doi>10.1145/1240624.1240850
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

This paper presents a quantitative human performance model of making single-stroke pen gestures within certain error constraints in terms of production time. Computed from the properties of Curves, Line segments, and Corners (CLC) in a gesture stroke, the model may serve as a foundation for the design and evaluation of existing and future gesture-based user interfaces at the basic motor control efficiency level, similar to the role of previous "laws of action" played to pointing, crossing or steering-based user interfaces. We report and discuss our experimental results on establishing and validating the CLC model, together with other basic empirical findings in stroke gesture production.

collapse
Keystroke-level model for advanced mobile phone interaction
Paul Holleis, Friederike Otto, Heinrich Hussmann, Albrecht Schmidt
Pages: 1505-1514
doi>10.1145/1240624.1240851
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.

collapse
An extended keystroke level model (KLM) for predicting the visual demand of in-vehicle information systems
Michael Pettitt, Gary Burnett, Alan Stevens
Pages: 1515-1524
doi>10.1145/1240624.1240852
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

To assess the potential distraction of In-Vehicle Information Systems (IVIS), simple, low cost evaluation methods are required for use in early design stages. The occlusion technique evaluates IVIS tasks in interrupted vision conditions, aiming to predict likely visual demand. However, the technique necessitates performance-focused user trials utilising robust prototypes, and consequently has limitations as an economic evaluation method. HCI practitioners view the Keystroke Level Model (KLM) as a reliable and valid means of modelling human performance, not requiring empirical trials or working prototypes. This paper proposes an extended KLM, which aims to predict measures based on the occlusion protocol. To validate the new method, we compared results of an occlusion study with predictions based on the assumptions of the extended KLM. Analysis revealed significant correlations between observed and predicted results (R=0.93-0.98) and low error rates (7-13%). In conclusion, the extended KLM shows considerable merit as a first-pass design tool.

collapse
SESSION: Color/blind
Steve Feiner
Towards developing assistive haptic feedback for visually impaired internet users
Ravi Kuber, Wai Yu, Graham McAllister
Pages: 1525-1534
doi>10.1145/1240624.1240854
Full text: PDFPDF

Haptic technologies are thought to have the potential to help blind individuals overcome the challenges experienced when accessing the Web. This paper proposes a structured participatory-based approach for developing targeted haptic sensations for purposes of web page exploration, and reports preliminary results showing how HTML elements can be represented through the use of force-feedback. Findings are then compared with mappings from previous studies, demonstrating the need for providing tailored haptic sensations for blind Internet users. This research aims to culminate in a framework, encompassing a vocabulary of haptic sensations with accompanying recommendations for designers to reference when developing inclusive web solutions.

collapse
An interface to support color blind computer users
Luke Jefferson, Richard Harvey
Pages: 1535-1538
doi>10.1145/1240624.1240855
Full text: PDFPDF

A new method for adapting digital images so that they are suitable for color blind viewers is presented. In contrast to earlier automatic methods which formulate the problem of adapting images for color blind observers as one of optimization, we demonstrate how it is possible to allow a user to compute a very wide range of adaptations in reasonable time under the control of a single variable. We demonstrate how the algorithm can be delivered as an adaptive technology via a simple interface, and evaluate the efficacy of our method using psychovisual experiments with simulated color blind users and a standard color vision test.

collapse
An adaptive & adaptable approach to enhance web graphics accessibility for visually impaired people
Chui Chui Tan, Wai Yu, Graham McAllister
Pages: 1539-1542
doi>10.1145/1240624.1240856
Full text: PDFPDF

To date, efforts have been made to enable visually impaired people to gain access to graphics on the Internet. However, these studies only offer a solution for a specific type of graphic by using a fixed set of hardware. To address this, a design approach of an adaptive and adaptable architecture is introduced which adapts to different graphical content, input/output devices (including assistive technologies) and user's profile and preferences. This system brings the opportunity to visually impaired people to gain access to graphics via different modalities by providing an adequate accessibility interface and interaction based on their profiles and needs.

collapse
SESSION: Social influence
Elizabeth Churchill
Modeling the impact of shared visual information on collaborative reference
Darren Gergle, Carolyn P. Rose, Robert E. Kraut
Pages: 1543-1552
doi>10.1145/1240624.1240858
Full text: PDFPDF

A number of recent studies have demonstrated that groups benefit considerably from access to shared visual information. This is due, in part, to the communicative efficiencies provided by the shared visual context. However, a large gap exists between our current theoretical understanding and our existing models. We address this gap by developing a computational model that integrates linguistic cues with visual cues in a way that effectively models reference during tightly-coupled, task-oriented interactions. The results demonstrate that an integrated model significantly outperforms existing language-only and visual-only models. The findings can be used to inform and augment the development of conversational agents, applications that dynamically track discourse and collaborative interactions, and dialogue managers for natural language interfaces.

collapse
Similarity is more important than expertise: accent effects in speech interfaces
Nils Dahlbäck, QianYing Wang, Clifford Nass, Jenny Alwin
Pages: 1553-1556
doi>10.1145/1240624.1240859
Full text: PDFPDF

In a balanced between-participants experiment (N = 96) American and Swedish participants listened to tourist information on a website about an American or Swedish city presented in English with either an American or Swedish accent and evaluated the speakers' knowledge of the topic, the voice characteristics, and the information characteristics. Users preferred accents similar to their own. Similarity-attraction effects were so powerful that same-accents speakers were viewed as being more knowledgeable than different-accent speakers even when the information would be much better-known by the opposite-accent speaker. Implications for similarity-attraction overwhelming expertise are discussed.

collapse
Provoking sociability
Brooke Foucault, Helena M. Mentis, Phoebe Sengers, Devon Welles
Pages: 1557-1560
doi>10.1145/1240624.1240860
Full text: PDFPDF

In this study, we explore the potential usefulness of disturbing, uncomfortable systems, demonstrating that provocative technology can have a positive effect on social relationships. We designed and evaluated an agent-based system that collects user information by asking seemingly benign questions, and then uses it to spread false, strange gossip throughout an office space. We show that provocative interaction on-line can improve off-line sociability.

collapse
Social responses to virtual humans: implications for future interface design
Catherine Amine Zanbaka, Amy Catherine Ulinski, Paula Goolkasian, Larry F. Hodges
Pages: 1561-1570
doi>10.1145/1240624.1240861
Full text: PDFPDF

Do human-human social interactions carry over to human-virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head-mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers.

collapse
SESSION: Learning
Michael Twidale
Hard lessons: effort-inducing interfaces benefit spatial learning
Andy Cockburn, Per Ola Kristensson, Jason Alexander, Shumin Zhai
Pages: 1571-1580
doi>10.1145/1240624.1240863
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Interface designers normally strive for a design that minimises the user's effort. However, when the design's objective is to train users to interact with interfaces that are highly dependent on spatial properties (e.g. keypad layout or gesture shapes) we contend that designers should consider explicitly increasing the mental effort of interaction. To test the hypothesis that effort aids spatial memory, we designed a "frost-brushing" interface that forces the user to mentally retrieve spatial information, or to physically brush away the frost to obtain visual guidance. We report results from two experiments using virtual keypad interfaces -- the first concerns spatial location learning of buttons on the keypad, and the second concerns both location and trajectory learning of gesture shape. The results support our hypothesis, showing that the frost-brushing design improved spatial learning. The participants' subjective responses emphasised the connections between effort, engagement, boredom, frustration, and enjoyment, suggesting that effort requires careful parameterisation to maximise its effectiveness.

collapse
Multiple mice for retention tasks in disadvantaged schools
Udai Singh Pawar, Joyojeet Pal, Rahul Gupta, Kentaro Toyama
Pages: 1581-1590
doi>10.1145/1240624.1240864
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.

collapse
Strategies for accelerating on-line learning of hotkeys
Tovi Grossman, Pierre Dragicevic, Ravin Balakrishnan
Pages: 1591-1600
doi>10.1145/1240624.1240865
Full text: PDFPDF
Other formats:  Mp3 Audio onlyMp3 Audio only  Mp4 VideoMp4 Video

Hotkeys are extremely useful in leveraging expert performance, but learning them is a slow process. This paper investigates alternative menu designs that can motivate and help users remember associations between menu commands and hotkeys. Building upon previous work on paired-associate learning, we suggest that the transition to expert use can be accelerated by manipulating feedback and cost associated with menu selection. We evaluate five designs in a pilot study and then two of the most promising ones in a formal experiment, showing that the speed of hotkey learning can indeed be significantly increased with little modifications to the standard menu/hotkey paradigm.

collapse
